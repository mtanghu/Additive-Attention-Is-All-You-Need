{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from fastformerLM import FastformerForCausalLM, FastformerLMConfig\n",
    "from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "from datasets import load_dataset\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# t5 tokenzier, warning is nothing to worry about since we will group the texts\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c111c7ad2b848e3bb62db71c53cba2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-f37a0e1d2b8653e1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-11f852fec431ca73.arrow\n",
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-f34b03b1d56e9cb0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-75498eacd22f25cc.arrow\n",
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-0d438b212cccd491.arrow\n",
      "Loading cached processed dataset at C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-1ed91ef60323d639.arrow\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n",
    "column_names = raw_datasets[\"train\"].column_names\n",
    "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
    "block_size = 2048\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples[text_column_name])\n",
    "    return output\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=column_names,\n",
    "        )\n",
    "\n",
    "lm_dataset = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    desc=f\"Grouping texts in chunks of {block_size}\",\n",
    ")\n",
    "\n",
    "lm_dataset.set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    evaluation_strategy =\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    report_to = \"none\",\n",
    "    learning_rate = 5e-4, \n",
    "    num_train_epochs = 25,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    max_grad_norm = 1,\n",
    "    fp16 = True\n",
    ")\n",
    "# learning rates tried 1e-4, 5e-4, 1e-3\n",
    "# 5e-4 yielded best results on BOTH windowed additive attention and gpt in terms of validation loss\n",
    "\n",
    "config = FastformerLMConfig(\n",
    "    hidden_size = 128,\n",
    "    vocab_size = len(tokenizer),\n",
    "    n_positions = block_size,\n",
    "    n_heads = 4,\n",
    "    n_layer = 6,\n",
    "    use_local_att = False,\n",
    "    window_sizes = None,\n",
    "    hidden_dropout_prob = .1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Additive Attention adapted for causal language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = FastformerForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.6M'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in fast_model.parameters() if p.requires_grad)\n",
    "f'{(pytorch_total_params / 1e6):2.1f}M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1334\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='777' max='16675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  777/16675 01:11 < 24:23, 10.86 it/s, Epoch 1.16/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.085100</td>\n",
       "      <td>6.169738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-667\n",
      "Configuration saved in ./results\\checkpoint-667\\config.json\n",
      "Model weights saved in ./results\\checkpoint-667\\pytorch_model.bin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-142f4dfaccc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfast_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2481\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fast_trainer = Trainer(\n",
    "    model=fast_model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "fast_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "fast_model.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowed Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FastformerLMConfig(\n",
    "    hidden_size = 128,\n",
    "    vocab_size = len(tokenizer),\n",
    "    n_positions = block_size,\n",
    "    n_heads = 4,\n",
    "    n_layer = 6,\n",
    "    use_local_att = True,\n",
    "    window_sizes = None, # will be set automatically\n",
    "    hidden_dropout_prob = .1\n",
    ")\n",
    "window_model = FastformerForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.6M'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in window_model.parameters() if p.requires_grad)\n",
    "f'{(pytorch_total_params / 1e6):2.1f}M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1334\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16675' max='16675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16675/16675 28:30, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.347100</td>\n",
       "      <td>5.516892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.474100</td>\n",
       "      <td>5.106071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.188300</td>\n",
       "      <td>4.934887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.032700</td>\n",
       "      <td>4.826500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.902300</td>\n",
       "      <td>4.727061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.775200</td>\n",
       "      <td>4.619518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.650500</td>\n",
       "      <td>4.532951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.539000</td>\n",
       "      <td>4.457493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.448900</td>\n",
       "      <td>4.396458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.375300</td>\n",
       "      <td>4.356263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.310600</td>\n",
       "      <td>4.324305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.255600</td>\n",
       "      <td>4.298475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.206300</td>\n",
       "      <td>4.271787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.161900</td>\n",
       "      <td>4.252179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.122100</td>\n",
       "      <td>4.230712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.087000</td>\n",
       "      <td>4.220989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.055200</td>\n",
       "      <td>4.206671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.026200</td>\n",
       "      <td>4.199833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.001100</td>\n",
       "      <td>4.191422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.978200</td>\n",
       "      <td>4.183199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.957700</td>\n",
       "      <td>4.177568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.940600</td>\n",
       "      <td>4.173618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.925000</td>\n",
       "      <td>4.171552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.911500</td>\n",
       "      <td>4.171033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.900400</td>\n",
       "      <td>4.170748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-667\n",
      "Configuration saved in ./results\\checkpoint-667\\config.json\n",
      "Model weights saved in ./results\\checkpoint-667\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-1334\n",
      "Configuration saved in ./results\\checkpoint-1334\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1334\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-2001\n",
      "Configuration saved in ./results\\checkpoint-2001\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2001\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-2668\n",
      "Configuration saved in ./results\\checkpoint-2668\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2668\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-3335\n",
      "Configuration saved in ./results\\checkpoint-3335\\config.json\n",
      "Model weights saved in ./results\\checkpoint-3335\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-4002\n",
      "Configuration saved in ./results\\checkpoint-4002\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4002\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-4669\n",
      "Configuration saved in ./results\\checkpoint-4669\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4669\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-5336\n",
      "Configuration saved in ./results\\checkpoint-5336\\config.json\n",
      "Model weights saved in ./results\\checkpoint-5336\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-6003\n",
      "Configuration saved in ./results\\checkpoint-6003\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6003\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-6670\n",
      "Configuration saved in ./results\\checkpoint-6670\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6670\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-7337\n",
      "Configuration saved in ./results\\checkpoint-7337\\config.json\n",
      "Model weights saved in ./results\\checkpoint-7337\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-8004\n",
      "Configuration saved in ./results\\checkpoint-8004\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8004\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-8671\n",
      "Configuration saved in ./results\\checkpoint-8671\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8671\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-9338\n",
      "Configuration saved in ./results\\checkpoint-9338\\config.json\n",
      "Model weights saved in ./results\\checkpoint-9338\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-10005\n",
      "Configuration saved in ./results\\checkpoint-10005\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10005\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-10672\n",
      "Configuration saved in ./results\\checkpoint-10672\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10672\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-11339\n",
      "Configuration saved in ./results\\checkpoint-11339\\config.json\n",
      "Model weights saved in ./results\\checkpoint-11339\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-12006\n",
      "Configuration saved in ./results\\checkpoint-12006\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12006\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-12673\n",
      "Configuration saved in ./results\\checkpoint-12673\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12673\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-13340\n",
      "Configuration saved in ./results\\checkpoint-13340\\config.json\n",
      "Model weights saved in ./results\\checkpoint-13340\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-14007\n",
      "Configuration saved in ./results\\checkpoint-14007\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14007\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-14674\n",
      "Configuration saved in ./results\\checkpoint-14674\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14674\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-15341\n",
      "Configuration saved in ./results\\checkpoint-15341\\config.json\n",
      "Model weights saved in ./results\\checkpoint-15341\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-16008\n",
      "Configuration saved in ./results\\checkpoint-16008\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16008\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-16675\n",
      "Configuration saved in ./results\\checkpoint-16675\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16675\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-16675 (score: 4.170747756958008).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16675, training_loss=4.422909219218516, metrics={'train_runtime': 1712.8657, 'train_samples_per_second': 19.47, 'train_steps_per_second': 9.735, 'total_flos': 498206252236800.0, 'train_loss': 4.422909219218516, 'epoch': 25.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_trainer = Trainer(\n",
    "    model=window_model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "window_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32100, 128])\n",
      "torch.Size([32100])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([2048, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(p.shape) for p in window_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "window_model.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GPT2 (comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "config = GPT2Config(n_embd = 128, vocab_size=len(tokenizer),\n",
    "                    n_positions = block_size, n_layer = 6, n_head = 4,\n",
    "                    resid_pdrop = .1, embd_pdrop = .1, attn_pdrop = .1,\n",
    "                    use_cache = False \n",
    "                   )\n",
    "gpt_model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.6M'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in gpt_model.parameters() if p.requires_grad)\n",
    "f'{(pytorch_total_params / 1e6):2.1f}M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1334\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16675' max='16675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16675/16675 50:03, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.861600</td>\n",
       "      <td>5.130702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.155600</td>\n",
       "      <td>4.886001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.930100</td>\n",
       "      <td>4.756009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.772600</td>\n",
       "      <td>4.664287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.641200</td>\n",
       "      <td>4.586405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.528200</td>\n",
       "      <td>4.514636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.426800</td>\n",
       "      <td>4.464148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.336300</td>\n",
       "      <td>4.419113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.257400</td>\n",
       "      <td>4.382271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.187700</td>\n",
       "      <td>4.350220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.123600</td>\n",
       "      <td>4.323933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.067000</td>\n",
       "      <td>4.298260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.016000</td>\n",
       "      <td>4.274817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.970500</td>\n",
       "      <td>4.258477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.929200</td>\n",
       "      <td>4.239575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.890700</td>\n",
       "      <td>4.232153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.856300</td>\n",
       "      <td>4.219457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.825400</td>\n",
       "      <td>4.206522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.796900</td>\n",
       "      <td>4.193279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.771700</td>\n",
       "      <td>4.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.748900</td>\n",
       "      <td>4.184310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.728800</td>\n",
       "      <td>4.178603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.712000</td>\n",
       "      <td>4.173586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.697100</td>\n",
       "      <td>4.169468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.685500</td>\n",
       "      <td>4.168451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-667\n",
      "Configuration saved in ./results\\checkpoint-667\\config.json\n",
      "Model weights saved in ./results\\checkpoint-667\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-1334\n",
      "Configuration saved in ./results\\checkpoint-1334\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1334\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-2001\n",
      "Configuration saved in ./results\\checkpoint-2001\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2001\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-2668\n",
      "Configuration saved in ./results\\checkpoint-2668\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2668\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-3335\n",
      "Configuration saved in ./results\\checkpoint-3335\\config.json\n",
      "Model weights saved in ./results\\checkpoint-3335\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-4002\n",
      "Configuration saved in ./results\\checkpoint-4002\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4002\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-4669\n",
      "Configuration saved in ./results\\checkpoint-4669\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4669\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-5336\n",
      "Configuration saved in ./results\\checkpoint-5336\\config.json\n",
      "Model weights saved in ./results\\checkpoint-5336\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-6003\n",
      "Configuration saved in ./results\\checkpoint-6003\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6003\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-6670\n",
      "Configuration saved in ./results\\checkpoint-6670\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6670\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-7337\n",
      "Configuration saved in ./results\\checkpoint-7337\\config.json\n",
      "Model weights saved in ./results\\checkpoint-7337\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-8004\n",
      "Configuration saved in ./results\\checkpoint-8004\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8004\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-8671\n",
      "Configuration saved in ./results\\checkpoint-8671\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8671\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-9338\n",
      "Configuration saved in ./results\\checkpoint-9338\\config.json\n",
      "Model weights saved in ./results\\checkpoint-9338\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-10005\n",
      "Configuration saved in ./results\\checkpoint-10005\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10005\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-10672\n",
      "Configuration saved in ./results\\checkpoint-10672\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10672\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-11339\n",
      "Configuration saved in ./results\\checkpoint-11339\\config.json\n",
      "Model weights saved in ./results\\checkpoint-11339\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-12006\n",
      "Configuration saved in ./results\\checkpoint-12006\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12006\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-12673\n",
      "Configuration saved in ./results\\checkpoint-12673\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12673\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-13340\n",
      "Configuration saved in ./results\\checkpoint-13340\\config.json\n",
      "Model weights saved in ./results\\checkpoint-13340\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-14007\n",
      "Configuration saved in ./results\\checkpoint-14007\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14007\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-14674\n",
      "Configuration saved in ./results\\checkpoint-14674\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14674\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-15341\n",
      "Configuration saved in ./results\\checkpoint-15341\\config.json\n",
      "Model weights saved in ./results\\checkpoint-15341\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-16008\n",
      "Configuration saved in ./results\\checkpoint-16008\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16008\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 132\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-16675\n",
      "Configuration saved in ./results\\checkpoint-16675\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16675\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-16675 (score: 4.168450832366943).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16675, training_loss=4.196683962706147, metrics={'train_runtime': 3004.3346, 'train_samples_per_second': 11.101, 'train_steps_per_second': 5.55, 'total_flos': 487621813862400.0, 'train_loss': 4.196683962706147, 'epoch': 25.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_trainer = Trainer(\n",
    "    model=gpt_model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "gpt_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_num_param(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return f'{(total_params / 1e6):2.1f}M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1e8efc748dfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#loss1 = pd.DataFrame(fast_trainer.state.log_history[1::2]).set_index(\"epoch\")[\"eval_loss\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mloss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mloss3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpt_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m results = pd.DataFrame({#f\"Additive Attention ({format_num_param(fast_model)} parameters)\": loss1,\n\u001b[0;32m     10\u001b[0m                         \u001b[1;34mf\"Windowed Additive Attention ({format_num_param(window_model)} parameters)\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpt_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "\n",
    "#loss1 = pd.DataFrame(fast_trainer.state.log_history[1::2]).set_index(\"epoch\")[\"eval_loss\"]\n",
    "loss2 = pd.DataFrame(window_trainer.state.log_history[1::2]).set_index(\"epoch\")[\"eval_loss\"]\n",
    "loss3 = pd.DataFrame(gpt_trainer.state.log_history[1::2]).set_index(\"epoch\")[\"eval_loss\"]\n",
    "results = pd.DataFrame({#f\"Additive Attention ({format_num_param(fast_model)} parameters)\": loss1,\n",
    "                        f\"Windowed Additive Attention ({format_num_param(window_model)} parameters)\": loss2,\n",
    "                        f\"GPT2 ({format_num_param(gpt_model)} parameters)\": loss3\n",
    "                       })\n",
    "results.to_csv(\"preliminary_results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Windowed Additive Attention (5.6M parameters)</th>\n",
       "      <th>GPT2 (5.6M parameters)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>181.000566</td>\n",
       "      <td>169.135732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>136.729564</td>\n",
       "      <td>132.422969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>114.498691</td>\n",
       "      <td>116.280933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>100.602486</td>\n",
       "      <td>106.089926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>91.142480</td>\n",
       "      <td>98.141006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>84.815704</td>\n",
       "      <td>91.344314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>79.825519</td>\n",
       "      <td>86.846967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>77.103197</td>\n",
       "      <td>83.022585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>73.535628</td>\n",
       "      <td>80.019537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>71.818169</td>\n",
       "      <td>77.495526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>70.062904</td>\n",
       "      <td>75.484937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>69.085897</td>\n",
       "      <td>73.571648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>67.883111</td>\n",
       "      <td>71.866986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>66.629106</td>\n",
       "      <td>70.702237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>65.406312</td>\n",
       "      <td>69.378353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>65.381491</td>\n",
       "      <td>68.865368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>64.301398</td>\n",
       "      <td>67.996530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>63.902693</td>\n",
       "      <td>67.122712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>63.310203</td>\n",
       "      <td>66.239621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>63.168806</td>\n",
       "      <td>66.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>63.114972</td>\n",
       "      <td>65.648185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>62.821473</td>\n",
       "      <td>65.274581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>62.828662</td>\n",
       "      <td>64.947931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>62.667241</td>\n",
       "      <td>64.681028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>62.731431</td>\n",
       "      <td>64.615275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Windowed Additive Attention (5.6M parameters)  GPT2 (5.6M parameters)\n",
       "epoch                                                                       \n",
       "1.0                                       181.000566              169.135732\n",
       "2.0                                       136.729564              132.422969\n",
       "3.0                                       114.498691              116.280933\n",
       "4.0                                       100.602486              106.089926\n",
       "5.0                                        91.142480               98.141006\n",
       "6.0                                        84.815704               91.344314\n",
       "7.0                                        79.825519               86.846967\n",
       "8.0                                        77.103197               83.022585\n",
       "9.0                                        73.535628               80.019537\n",
       "10.0                                       71.818169               77.495526\n",
       "11.0                                       70.062904               75.484937\n",
       "12.0                                       69.085897               73.571648\n",
       "13.0                                       67.883111               71.866986\n",
       "14.0                                       66.629106               70.702237\n",
       "15.0                                       65.406312               69.378353\n",
       "16.0                                       65.381491               68.865368\n",
       "17.0                                       64.301398               67.996530\n",
       "18.0                                       63.902693               67.122712\n",
       "19.0                                       63.310203               66.239621\n",
       "20.0                                       63.168806               66.088877\n",
       "21.0                                       63.114972               65.648185\n",
       "22.0                                       62.821473               65.274581\n",
       "23.0                                       62.828662               64.947931\n",
       "24.0                                       62.667241               64.681028\n",
       "25.0                                       62.731431               64.615275"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_results = np.exp(results)\n",
    "ppl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppl_results.plot()\n",
    "\n",
    "plt.ylabel(\"Validation Perplexity\")\n",
    "plt.axhline(y=ppl_results[f\"Windowed Additive Attention ({format_num_param(window_model)} parameters)\"].min(),\n",
    "            linestyle='--', label = \"Minimum Windowed Additive Attention Validation Perplexity\", color = 'C1')\n",
    "plt.legend()\n",
    "plt.savefig('preliminary_results.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set evaluation (DO NOT TUNE ON THIS, SHOULD ONLY BE RUN FOR BENCHMARKING PURPOSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 151\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.76095518489554"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_model.cuda()\n",
    "result = fast_trainer.evaluate(lm_dataset[\"test\"])\n",
    "torch.e**result[\"eval_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 151\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60.07999348134555"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_model.cuda()\n",
    "result = window_trainer.evaluate(lm_dataset[\"test\"])\n",
    "torch.e**result[\"eval_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7115c775ed24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgpt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpt_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpt_model' is not defined"
     ]
    }
   ],
   "source": [
    "gpt_model.cuda()\n",
    "result = gpt_trainer.evaluate(lm_dataset[\"test\"])\n",
    "torch.e**result[\"eval_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test code to try some text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_number = 94\n",
    "\n",
    "# input_ids = lm_dataset[\"test\"][test_number][\"input_ids\"].reshape(1, -1).cpu()\n",
    "# attention_mask = lm_dataset[\"test\"][test_number][\"attention_mask\"].reshape(1, -1).cpu()\n",
    "# labels = lm_dataset[\"test\"][test_number][\"labels\"].reshape(1, -1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = window_model\n",
    "\n",
    "# test_model = test_model.cpu().eval()\n",
    "# out = test_model(input_ids=input_ids, labels = labels, attention_mask = attention_mask)\n",
    "# logits = out.logits\n",
    "# loss = out.loss\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.batch_decode(input_ids[:,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_tokens = test_model.generate(input_ids[:,:50], attention_mask = attention_mask, do_sample=True, max_length=256, temperature = .7)\n",
    "# tokenizer.batch_decode(generated_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tuning\n",
    "Short little experiment to see if other window sizes would work better, it seems the heuristic currently is use is very good and not much else performed better. The heuristic chosen after some mild testing is that window sizes should be $4*(2^{hidden layer number})$ with the last layer being global attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperparameters\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir = \"./results\",\n",
    "#     logging_strategy = \"epoch\",\n",
    "#     evaluation_strategy =\"epoch\",\n",
    "#     save_strategy = \"epoch\",\n",
    "#     report_to = \"none\",\n",
    "#     learning_rate = 5e-4,\n",
    "#     num_train_epochs = 1,\n",
    "#     per_device_train_batch_size = 2,\n",
    "#     per_device_eval_batch_size = 2,\n",
    "#     load_best_model_at_end = True,\n",
    "#     metric_for_best_model = \"eval_loss\",\n",
    "#     max_grad_norm = 1,\n",
    "#     fp16 = True,\n",
    "#     lr_scheduler_type = \"constant\"\n",
    "# )\n",
    "\n",
    "# config = FastformerLMConfig(\n",
    "#     hidden_size = 128,\n",
    "#     vocab_size = len(tokenizer),\n",
    "#     n_positions = block_size,\n",
    "#     n_heads = 4,\n",
    "#     n_layer = 6,\n",
    "#     use_local_att = True,\n",
    "#     window_sizes = None, # set during tuning\n",
    "#     hidden_dropout_prob = .1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import torch\n",
    "# logging.disable(logging.INFO)\n",
    "\n",
    "# import random\n",
    "# r = random.Random(2)\n",
    "# options = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "# results = []\n",
    "# while True:\n",
    "#     config.window_sizes = r.choices(options, k=6)\n",
    "    \n",
    "#     fast_model = FastformerForCausalLM(config)\n",
    "#     fast_trainer = Trainer(\n",
    "#         model=fast_model,\n",
    "#         args=training_args,\n",
    "#         data_collator=default_data_collator,\n",
    "#         train_dataset=lm_dataset[\"train\"],\n",
    "#         eval_dataset=lm_dataset[\"validation\"]\n",
    "#     )\n",
    "\n",
    "#     fast_trainer.train()\n",
    "#     result = {\"window_sizes\": config.window_sizes, \"loss\": fast_trainer.state.best_metric}\n",
    "#     results.append(result)\n",
    "    \n",
    "#     print(result)\n",
    "#     del fast_model\n",
    "#     del fast_trainer\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(results).sort_values(by = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
