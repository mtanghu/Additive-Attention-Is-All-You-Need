{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from leap import LeapForCausalLM, LeapConfig\n",
    "from lstm import LstmForCausalLM\n",
    "from transformers import (PreTrainedTokenizerFast, TrainingArguments, Trainer,\n",
    "                          EarlyStoppingCallback, default_data_collator,\n",
    "                          GPT2Config, GPT2LMHeadModel)\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# word level tokenizer as per wikitext modeling\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from itertools import chain\n",
    "import logging\n",
    "logging.disable(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (C:\\Users\\micha\\.cache\\huggingface\\datasets\\wikitext\\wikitext-103-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d42bc76c89439291b801137877b4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# globals\n",
    "raw_datasets = load_dataset(\"wikitext\", \"wikitext-103-v1\", split = [\"train[:10%]\", \"validation\", \"test\"])\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": raw_datasets[0],\n",
    "    \"validation\": raw_datasets[1],\n",
    "    \"test\": raw_datasets[2]\n",
    "})\n",
    "\n",
    "total_train_tokens = 10416407 # see appendix at the end of notebook\n",
    "max_num_params = 115476240\n",
    "param_data_ratio = max_num_params**.74 / total_train_tokens\n",
    "seq_len = 1024\n",
    "subset_datasets = raw_datasets\n",
    "\n",
    "# hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    report_to = \"none\",\n",
    "    learning_rate = 5e-4,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = .05,\n",
    "    num_train_epochs = 20,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    max_grad_norm = 1,\n",
    "    fp16 = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-0baa55087bc50208.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-6eac8a2ae7639342.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-74f5150031e97cdd.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-d88b35938dba8cca.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-211b636aa7781133.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-8f97faedd7f66d6d.arrow\n"
     ]
    }
   ],
   "source": [
    "# make a word level tokenizer\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.enable_padding(pad_id = 0, pad_token = \"<pad>\")\n",
    "# no post processing\n",
    "\n",
    "# WE USE A SET VOCAB SIZE OF 8,192 FOR SPEED (the oov should only be around 5%)\n",
    "token_trainer = WordLevelTrainer(vocab_size = 8191, # -1 for pad token\n",
    "                                 special_tokens = [\"<unk>\"])\n",
    "\n",
    "def batch_iterator(batch_size=10000):\n",
    "    text = raw_datasets[\"train\"]['text']\n",
    "    for i in range(0, len(text), batch_size):\n",
    "        yield text[i : i + batch_size]\n",
    "\n",
    "tokenizer.train_from_iterator(batch_iterator(),\n",
    "                              trainer = token_trainer,\n",
    "                              length=len(raw_datasets[\"train\"][\"text\"]))\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer, pad_token = \"<pad>\")\n",
    "\n",
    "# tokenized the dataset\n",
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples[\"text\"])\n",
    "    return output\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns = \"text\",\n",
    "    desc=f\"tokenize dataset\"\n",
    ")\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + seq_len] for i in range(0, total_length, seq_len)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    # for language modeling, inputs are labels (they will be shifted inside the model)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    \n",
    "    # pad last block with 0\n",
    "    last_ids = result[\"input_ids\"][-1]\n",
    "    diff = seq_len - len(last_ids)\n",
    "    result[\"input_ids\"][-1] = last_ids + [0 for _ in range(diff)]\n",
    "    \n",
    "    # set attention mask to mask out these tokens\n",
    "    result[\"attention_mask\"][-1] = result[\"attention_mask\"][-1] + [0 for _ in range(diff)]\n",
    "    \n",
    "    # set pad labels to -100 so they will be ignored by CrossEntropyLoss\n",
    "    result[\"labels\"][-1] = result[\"labels\"][-1] + [-100 for _ in range(diff)]\n",
    "    return result\n",
    "\n",
    "# set globally block size for group texts function\n",
    "lm_dataset = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    desc=f\"Grouping texts in chunks of {seq_len}\"\n",
    ")\n",
    "\n",
    "lm_dataset = lm_dataset.remove_columns([\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(dataset, num_parameters, param_data_ratio):\n",
    "    dataset = DatasetDict(copy.deepcopy(dataset))\n",
    "    subset_num_tokens = num_parameters**.74 / param_data_ratio\n",
    "    \n",
    "    # add rows until we meet the subset_num_tokens\n",
    "    training_set = dataset[\"train\"]\n",
    "    total_tokens = 0\n",
    "    for i, row in enumerate(training_set):\n",
    "        total_tokens += len(row[\"input_ids\"])\n",
    "        \n",
    "        if total_tokens >= subset_num_tokens:\n",
    "            print(f'NUMBER OF TOKENS: {total_tokens:,}')\n",
    "            break\n",
    "            \n",
    "    dataset[\"train\"] = Dataset.from_dict(training_set[:i+1])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(hidden_size, n_head = None, gpt = False, rnn = False):\n",
    "    # calculate number of layers needed based on levine 2020\n",
    "    n_layer = round((math.log(hidden_size) - 5.039) / 5.55e-2)\n",
    "    n_layer = max(1, n_layer)\n",
    "    print(f'Using {n_layer} layers')\n",
    "    \n",
    "    # get number of parameters\n",
    "    if gpt is True:\n",
    "        config = GPT2Config(\n",
    "            n_embd = hidden_size, n_layer = n_layer,\n",
    "            n_head = 1, vocab_size = 0, n_positions = 0\n",
    "        )\n",
    "        model = GPT2LMHeadModel(config)\n",
    "    elif rnn is True:\n",
    "        model = LstmForCausalLM(\n",
    "            hidden_size = hidden_size,\n",
    "            n_layer = n_layer,\n",
    "            vocab_size = 0\n",
    "        )\n",
    "    else:\n",
    "        config = LeapConfig(\n",
    "            hidden_size = hidden_size, n_layer = n_layer,\n",
    "            n_head = n_head, vocab_size = 0, n_positions = 0\n",
    "        )\n",
    "        model = LeapForCausalLM(config)\n",
    "\n",
    "    non_embedding_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'NON EMBEDDING PARAMETERS: {non_embedding_parameters:,}')\n",
    "\n",
    "    # subset dataset using global lm_dataset\n",
    "    global lm_dataset\n",
    "    subset_datasets = subset_data(lm_dataset, non_embedding_parameters, param_data_ratio)\n",
    "\n",
    "    if gpt is True:\n",
    "        config = GPT2Config(\n",
    "            n_embd = hidden_size, n_layer = n_layer, n_head = n_head,\n",
    "            vocab_size = len(tokenizer) + 1, n_positions = seq_len,\n",
    "            initializer_range = 1 / hidden_size**.5\n",
    "        )\n",
    "        model = GPT2LMHeadModel(config)\n",
    "    elif rnn is True:\n",
    "        model = LstmForCausalLM(\n",
    "            hidden_size = hidden_size,\n",
    "            n_layer = n_layer,\n",
    "            vocab_size = len(tokenizer) + 1,\n",
    "        )\n",
    "    else:\n",
    "        config = LeapConfig(\n",
    "            hidden_size = hidden_size, n_layer = n_layer, n_head = n_head,\n",
    "            vocab_size = len(tokenizer) + 1, n_positions = seq_len,\n",
    "            use_local_att = True, window_sizes = None, rescale = 10,\n",
    "            initializer_range = 1 / hidden_size**.5,\n",
    "        )\n",
    "        model = LeapForCausalLM(config)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=default_data_collator,\n",
    "        train_dataset=subset_datasets[\"train\"],\n",
    "        eval_dataset=subset_datasets[\"validation\"],\n",
    "        callbacks = [EarlyStoppingCallback]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\n===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\\n\")\n",
    "    print(f'Numeric form: {int(trainer.state.total_flos)}\\nHuman Readable: {int(trainer.state.total_flos):,}')\n",
    "\n",
    "    print(\"\\n===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\\n\")\n",
    "    print(trainer.evaluate(subset_datasets[\"test\"]))\n",
    "\n",
    "    # save gpu memory\n",
    "    del trainer\n",
    "    del model\n",
    "    del subset_datasets\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAP TRAINING\n",
    "Each run is done seperately in it's own cell just for easy viewing of logs and in case something goes wrong (OOM errors or training issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 49,856\n",
      "NUMBER OF TOKENS: 33,792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='255' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [255/340 00:17 < 00:05, 14.18 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.216000</td>\n",
       "      <td>8.726050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.315100</td>\n",
       "      <td>7.873346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.604800</td>\n",
       "      <td>7.315463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.045500</td>\n",
       "      <td>6.896474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.616700</td>\n",
       "      <td>6.619842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.330200</td>\n",
       "      <td>6.449937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.149100</td>\n",
       "      <td>6.371703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.042700</td>\n",
       "      <td>6.316381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.979000</td>\n",
       "      <td>6.295048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.934400</td>\n",
       "      <td>6.281782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.899200</td>\n",
       "      <td>6.273685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.884500</td>\n",
       "      <td>6.271132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.879600</td>\n",
       "      <td>6.269254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.858100</td>\n",
       "      <td>6.267292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.844000</td>\n",
       "      <td>6.268411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 151626055680\n",
      "Human Readable: 151,626,055,680\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.197883129119873, 'eval_runtime': 0.9018, 'eval_samples_per_second': 263.919, 'eval_steps_per_second': 131.959, 'epoch': 15.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, n_head = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 111,648\n",
      "NUMBER OF TOKENS: 61,440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/600 00:07 < 00:21, 20.59 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.933500</td>\n",
       "      <td>7.853873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.173700</td>\n",
       "      <td>6.631284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.244100</td>\n",
       "      <td>6.277154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.972900</td>\n",
       "      <td>6.237168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.904900</td>\n",
       "      <td>6.254429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 205789593600\n",
      "Human Readable: 205,789,593,600\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.165459632873535, 'eval_runtime': 1.0394, 'eval_samples_per_second': 228.989, 'eval_steps_per_second': 114.494, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 96, n_head = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 198,016\n",
      "NUMBER OF TOKENS: 94,208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='506' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [506/920 00:19 < 00:15, 26.00 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.737100</td>\n",
       "      <td>7.288536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.452100</td>\n",
       "      <td>6.222474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.956200</td>\n",
       "      <td>6.216580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.912400</td>\n",
       "      <td>6.205697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.858100</td>\n",
       "      <td>6.155235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.793500</td>\n",
       "      <td>6.120760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.733700</td>\n",
       "      <td>6.091662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.680500</td>\n",
       "      <td>6.081302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.631000</td>\n",
       "      <td>6.051317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.592300</td>\n",
       "      <td>6.032889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.557300</td>\n",
       "      <td>6.042084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1231209627648\n",
      "Human Readable: 1,231,209,627,648\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.965877532958984, 'eval_runtime': 0.9655, 'eval_samples_per_second': 246.495, 'eval_steps_per_second': 123.247, 'epoch': 11.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, n_head = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 308,960\n",
      "NUMBER OF TOKENS: 130,048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 640/1280 00:19 < 00:20, 31.99 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.217600</td>\n",
       "      <td>6.536333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.106200</td>\n",
       "      <td>6.202743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.977900</td>\n",
       "      <td>6.182458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.905800</td>\n",
       "      <td>6.111916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.834000</td>\n",
       "      <td>6.070071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.758800</td>\n",
       "      <td>6.043207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.704200</td>\n",
       "      <td>6.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.633000</td>\n",
       "      <td>5.989629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.582600</td>\n",
       "      <td>5.956466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.532900</td>\n",
       "      <td>5.984838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2410777804800\n",
      "Human Readable: 2,410,777,804,800\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.882508754730225, 'eval_runtime': 0.8682, 'eval_samples_per_second': 274.115, 'eval_steps_per_second': 137.058, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, n_head = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1,776,768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 475,136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4408' max='4640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4408/4640 03:32 < 00:11, 20.74 it/s, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.843000</td>\n",
       "      <td>6.099133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.864200</td>\n",
       "      <td>5.755672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.608900</td>\n",
       "      <td>5.576675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.425200</td>\n",
       "      <td>5.444574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.261200</td>\n",
       "      <td>5.324715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.114900</td>\n",
       "      <td>5.233246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.985100</td>\n",
       "      <td>5.166789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.877400</td>\n",
       "      <td>5.104250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.779300</td>\n",
       "      <td>5.065774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.696500</td>\n",
       "      <td>5.012495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.623700</td>\n",
       "      <td>4.984278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.561700</td>\n",
       "      <td>4.971418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.509000</td>\n",
       "      <td>4.959350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.465400</td>\n",
       "      <td>4.946453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.429100</td>\n",
       "      <td>4.941850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.402700</td>\n",
       "      <td>4.931950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.383600</td>\n",
       "      <td>4.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.368900</td>\n",
       "      <td>4.926436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.361600</td>\n",
       "      <td>4.927012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 96239534211072\n",
      "Human Readable: 96,239,534,211,072\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.866719722747803, 'eval_runtime': 1.7209, 'eval_samples_per_second': 138.303, 'eval_steps_per_second': 69.152, 'epoch': 19.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, n_head = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n",
      "NON EMBEDDING PARAMETERS: 7,099,136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1,323,008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10982' max='12920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10982/12920 15:50 < 02:47, 11.56 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.298800</td>\n",
       "      <td>5.666354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.456600</td>\n",
       "      <td>5.243888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.092200</td>\n",
       "      <td>4.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.839400</td>\n",
       "      <td>4.794570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.647300</td>\n",
       "      <td>4.687461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.491900</td>\n",
       "      <td>4.594444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.356600</td>\n",
       "      <td>4.516050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.232600</td>\n",
       "      <td>4.461733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.120400</td>\n",
       "      <td>4.412426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.018200</td>\n",
       "      <td>4.391651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.926200</td>\n",
       "      <td>4.364927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.843000</td>\n",
       "      <td>4.349786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.771300</td>\n",
       "      <td>4.339295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>4.337113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.657200</td>\n",
       "      <td>4.336897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.616000</td>\n",
       "      <td>4.335644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.585500</td>\n",
       "      <td>4.336129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 958005799550976\n",
      "Human Readable: 958,005,799,550,976\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.3101677894592285, 'eval_runtime': 2.8093, 'eval_samples_per_second': 84.72, 'eval_steps_per_second': 42.36, 'epoch': 17.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 256, n_head = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 16,012,480\n",
      "NUMBER OF TOKENS: 2,414,592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12969' max='23580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12969/23580 25:08 < 20:34, 8.59 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.014600</td>\n",
       "      <td>5.466545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.193700</td>\n",
       "      <td>4.929879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.774700</td>\n",
       "      <td>4.638540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.508600</td>\n",
       "      <td>4.457870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.303800</td>\n",
       "      <td>4.331307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.129400</td>\n",
       "      <td>4.228373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.977600</td>\n",
       "      <td>4.165196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.840900</td>\n",
       "      <td>4.119393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.717800</td>\n",
       "      <td>4.090394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.602700</td>\n",
       "      <td>4.069636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.495500</td>\n",
       "      <td>4.073772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2551798003138560\n",
      "Human Readable: 2,551,798,003,138,560\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.044043064117432, 'eval_runtime': 4.134, 'eval_samples_per_second': 57.571, 'eval_steps_per_second': 28.785, 'epoch': 11.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 320, n_head = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 22 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 69,308,416\n",
      "NUMBER OF TOKENS: 7,139,328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6972' max='69720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6972/69720 29:45 < 4:27:57, 3.90 it/s, Epoch 2/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.585300</td>\n",
       "      <td>4.997616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.929600</td>\n",
       "      <td>6.358079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 5937786179813376\n",
      "Human Readable: 5,937,786,179,813,376\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.929450511932373, 'eval_runtime': 10.0663, 'eval_samples_per_second': 23.643, 'eval_steps_per_second': 11.822, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 512, n_head = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 25 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 115,460,740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9920' max='99200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9920/99200 59:04 < 8:51:49, 2.80 it/s, Epoch 2/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.994600</td>\n",
       "      <td>6.520983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.750900</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 14072894423777280\n",
      "Human Readable: 14,072,894,423,777,280\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.514883041381836, 'eval_runtime': 14.1285, 'eval_samples_per_second': 16.845, 'eval_steps_per_second': 8.423, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 620, n_head = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 50,112\n",
      "NUMBER OF TOKENS: 34,816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 00:21, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.372500</td>\n",
       "      <td>8.864362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.409400</td>\n",
       "      <td>7.915650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.630200</td>\n",
       "      <td>7.324174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.044600</td>\n",
       "      <td>6.885992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.614800</td>\n",
       "      <td>6.588628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.309600</td>\n",
       "      <td>6.400613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.110800</td>\n",
       "      <td>6.289826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.980500</td>\n",
       "      <td>6.236464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.901300</td>\n",
       "      <td>6.206777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.837000</td>\n",
       "      <td>6.188633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.792400</td>\n",
       "      <td>6.176302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.766100</td>\n",
       "      <td>6.170948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.742700</td>\n",
       "      <td>6.168391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.725200</td>\n",
       "      <td>6.163882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.713000</td>\n",
       "      <td>6.161460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.703500</td>\n",
       "      <td>6.160170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.694500</td>\n",
       "      <td>6.159438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.696200</td>\n",
       "      <td>6.158488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.690900</td>\n",
       "      <td>6.158330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.690400</td>\n",
       "      <td>6.158334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 209363927040\n",
      "Human Readable: 209,363,927,040\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.0926971435546875, 'eval_runtime': 0.8163, 'eval_samples_per_second': 291.566, 'eval_steps_per_second': 145.783, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, n_head = 1, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 112,032\n",
      "NUMBER OF TOKENS: 61,440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/600 00:13 < 00:13, 22.79 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.919500</td>\n",
       "      <td>7.813031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.095200</td>\n",
       "      <td>6.567191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.185100</td>\n",
       "      <td>6.218553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.906300</td>\n",
       "      <td>6.150863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.799200</td>\n",
       "      <td>6.114497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.719400</td>\n",
       "      <td>6.070238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.651000</td>\n",
       "      <td>6.044841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.599100</td>\n",
       "      <td>6.035303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.550200</td>\n",
       "      <td>6.023751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.507200</td>\n",
       "      <td>6.024307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 412994764800\n",
      "Human Readable: 412,994,764,800\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.943718433380127, 'eval_runtime': 0.8089, 'eval_samples_per_second': 294.228, 'eval_steps_per_second': 147.114, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 96, n_head = 1, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 198,528\n",
      "NUMBER OF TOKENS: 94,208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='552' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [552/920 00:19 < 00:12, 28.62 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.185300</td>\n",
       "      <td>6.763832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.164000</td>\n",
       "      <td>6.108711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.788300</td>\n",
       "      <td>6.011187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.656500</td>\n",
       "      <td>5.964048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.554100</td>\n",
       "      <td>5.920763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.467400</td>\n",
       "      <td>5.896141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.388800</td>\n",
       "      <td>5.879999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.311300</td>\n",
       "      <td>5.872243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.237800</td>\n",
       "      <td>5.866170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.166600</td>\n",
       "      <td>5.861701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.105400</td>\n",
       "      <td>5.855399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.051000</td>\n",
       "      <td>5.856228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1346610659328\n",
      "Human Readable: 1,346,610,659,328\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.780641555786133, 'eval_runtime': 0.7975, 'eval_samples_per_second': 298.42, 'eval_steps_per_second': 149.21, 'epoch': 12.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, n_head = 2, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 309,600\n",
      "NUMBER OF TOKENS: 131,072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 640/1280 00:19 < 00:19, 32.75 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.885200</td>\n",
       "      <td>6.259148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.919800</td>\n",
       "      <td>5.952970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.683400</td>\n",
       "      <td>5.865604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.540600</td>\n",
       "      <td>5.813881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.418200</td>\n",
       "      <td>5.770795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.296700</td>\n",
       "      <td>5.737412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.181600</td>\n",
       "      <td>5.723117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.072100</td>\n",
       "      <td>5.710388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.973000</td>\n",
       "      <td>5.702203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.885800</td>\n",
       "      <td>5.708678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2434793472000\n",
      "Human Readable: 2,434,793,472,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.621386528015137, 'eval_runtime': 0.8283, 'eval_samples_per_second': 287.337, 'eval_steps_per_second': 143.669, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, n_head = 2, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1,779,840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 475,136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='4640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/4640 01:54 < 01:54, 20.27 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.583500</td>\n",
       "      <td>5.733374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>5.458075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.236400</td>\n",
       "      <td>5.299707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.034200</td>\n",
       "      <td>5.194823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.875200</td>\n",
       "      <td>5.148612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.739800</td>\n",
       "      <td>5.113988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.620600</td>\n",
       "      <td>5.096081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.509500</td>\n",
       "      <td>5.091672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.407800</td>\n",
       "      <td>5.091411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.313600</td>\n",
       "      <td>5.094698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 50739963494400\n",
      "Human Readable: 50,739,963,494,400\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.021527290344238, 'eval_runtime': 1.5064, 'eval_samples_per_second': 157.994, 'eval_steps_per_second': 78.997, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, n_head = 3, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n",
      "NON EMBEDDING PARAMETERS: 7,108,352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1,324,032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7764' max='12940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7764/12940 13:38 < 09:06, 9.48 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.930500</td>\n",
       "      <td>5.335121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.119000</td>\n",
       "      <td>5.016593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.858500</td>\n",
       "      <td>4.893312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.696700</td>\n",
       "      <td>4.804842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.556600</td>\n",
       "      <td>4.740015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.425000</td>\n",
       "      <td>4.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.302100</td>\n",
       "      <td>4.648248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>4.597099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.066400</td>\n",
       "      <td>4.570751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.955100</td>\n",
       "      <td>4.558356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.849600</td>\n",
       "      <td>4.549649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.751600</td>\n",
       "      <td>4.550180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 677641357099008\n",
      "Human Readable: 677,641,357,099,008\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.513540744781494, 'eval_runtime': 3.4159, 'eval_samples_per_second': 69.675, 'eval_steps_per_second': 34.838, 'epoch': 12.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 256, n_head = 4, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 16,029,120\n",
      "NUMBER OF TOKENS: 2,416,640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14160' max='23600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14160/23600 38:58 < 25:58, 6.06 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.643600</td>\n",
       "      <td>5.090171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.922700</td>\n",
       "      <td>4.822154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.681500</td>\n",
       "      <td>4.652691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.482600</td>\n",
       "      <td>4.513328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.294600</td>\n",
       "      <td>4.391515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.118900</td>\n",
       "      <td>4.264635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.954500</td>\n",
       "      <td>4.181118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.808900</td>\n",
       "      <td>4.126382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.674700</td>\n",
       "      <td>4.079720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.551600</td>\n",
       "      <td>4.068955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.435400</td>\n",
       "      <td>4.057515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.325500</td>\n",
       "      <td>4.060906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2789036104089600\n",
      "Human Readable: 2,789,036,104,089,600\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.040293216705322, 'eval_runtime': 5.5647, 'eval_samples_per_second': 42.769, 'eval_steps_per_second': 21.385, 'epoch': 12.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 320, n_head = 5, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 45,872,064\n",
      "NUMBER OF TOKENS: 5,261,312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28259' max='51380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28259/51380 2:22:49 < 1:56:51, 3.30 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.314400</td>\n",
       "      <td>4.868124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.704400</td>\n",
       "      <td>4.584350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.431700</td>\n",
       "      <td>4.307031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.124600</td>\n",
       "      <td>4.053065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.878800</td>\n",
       "      <td>3.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.692600</td>\n",
       "      <td>3.793347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.539100</td>\n",
       "      <td>3.735225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.402600</td>\n",
       "      <td>3.679291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.273900</td>\n",
       "      <td>3.666333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.661678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.028600</td>\n",
       "      <td>3.678471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 15928917892005888\n",
      "Human Readable: 15,928,917,892,005,888\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.634080410003662, 'eval_runtime': 10.9414, 'eval_samples_per_second': 21.752, 'eval_steps_per_second': 10.876, 'epoch': 11.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 448, n_head = 7, gpt = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 33,408\n",
      "NUMBER OF TOKENS: 25,600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:13, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30.315800</td>\n",
       "      <td>29.109987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27.620100</td>\n",
       "      <td>26.192972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24.975500</td>\n",
       "      <td>24.049240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22.910600</td>\n",
       "      <td>22.105282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20.867700</td>\n",
       "      <td>20.157061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18.927100</td>\n",
       "      <td>18.141685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>17.005400</td>\n",
       "      <td>16.385288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>15.575000</td>\n",
       "      <td>15.186225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>14.599200</td>\n",
       "      <td>14.355819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.844300</td>\n",
       "      <td>13.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13.290300</td>\n",
       "      <td>13.317054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12.903600</td>\n",
       "      <td>12.994419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12.591800</td>\n",
       "      <td>12.744621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>12.376000</td>\n",
       "      <td>12.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>12.176800</td>\n",
       "      <td>12.435946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>12.063500</td>\n",
       "      <td>12.351574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>11.989900</td>\n",
       "      <td>12.299751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>11.991500</td>\n",
       "      <td>12.272884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>11.954900</td>\n",
       "      <td>12.262307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>11.944600</td>\n",
       "      <td>12.260607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 102629376000\n",
      "Human Readable: 102,629,376,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 12.191839218139648, 'eval_runtime': 3.3843, 'eval_samples_per_second': 70.325, 'eval_steps_per_second': 35.162, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 74,688\n",
      "NUMBER OF TOKENS: 46,080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 01:28, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>36.664000</td>\n",
       "      <td>33.235603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29.132200</td>\n",
       "      <td>25.595917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>21.868300</td>\n",
       "      <td>18.297552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16.462700</td>\n",
       "      <td>15.074944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>14.017900</td>\n",
       "      <td>13.292471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12.470300</td>\n",
       "      <td>12.100291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>11.389600</td>\n",
       "      <td>11.238749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10.549000</td>\n",
       "      <td>10.578231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.920400</td>\n",
       "      <td>10.035317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9.381700</td>\n",
       "      <td>9.616461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>8.978000</td>\n",
       "      <td>9.299934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8.665200</td>\n",
       "      <td>9.063387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>8.453500</td>\n",
       "      <td>8.890419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>8.286200</td>\n",
       "      <td>8.768717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>8.159000</td>\n",
       "      <td>8.683068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8.074000</td>\n",
       "      <td>8.628024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>8.034400</td>\n",
       "      <td>8.594037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>8.010200</td>\n",
       "      <td>8.576362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>7.973500</td>\n",
       "      <td>8.569660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.977000</td>\n",
       "      <td>8.568624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 412994764800\n",
      "Human Readable: 412,994,764,800\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.518646240234375, 'eval_runtime': 3.4943, 'eval_samples_per_second': 68.112, 'eval_steps_per_second': 34.056, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 96, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 132,352\n",
      "NUMBER OF TOKENS: 69,632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='680' max='680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [680/680 01:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>40.393800</td>\n",
       "      <td>34.380318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27.984200</td>\n",
       "      <td>22.011951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18.024300</td>\n",
       "      <td>16.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14.158300</td>\n",
       "      <td>13.293620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11.868000</td>\n",
       "      <td>11.476675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10.286800</td>\n",
       "      <td>10.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.230200</td>\n",
       "      <td>9.465310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.511400</td>\n",
       "      <td>8.924860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.007500</td>\n",
       "      <td>8.546611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.629400</td>\n",
       "      <td>8.253380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7.343400</td>\n",
       "      <td>8.037686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.127300</td>\n",
       "      <td>7.870688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.963500</td>\n",
       "      <td>7.755872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.845400</td>\n",
       "      <td>7.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.760100</td>\n",
       "      <td>7.612543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.701300</td>\n",
       "      <td>7.574136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.663500</td>\n",
       "      <td>7.553673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>6.640900</td>\n",
       "      <td>7.541223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6.629900</td>\n",
       "      <td>7.536741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.626200</td>\n",
       "      <td>7.535952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1105912135680\n",
      "Human Readable: 1,105,912,135,680\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.374115467071533, 'eval_runtime': 3.5662, 'eval_samples_per_second': 66.737, 'eval_steps_per_second': 33.369, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 206,400\n",
      "NUMBER OF TOKENS: 97,280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 02:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>40.694700</td>\n",
       "      <td>30.122379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>15.083302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.789600</td>\n",
       "      <td>11.748950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.283200</td>\n",
       "      <td>9.948137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8.793000</td>\n",
       "      <td>8.878134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.895200</td>\n",
       "      <td>8.216182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.311800</td>\n",
       "      <td>7.799478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.931400</td>\n",
       "      <td>7.523981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.646700</td>\n",
       "      <td>7.306419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.445200</td>\n",
       "      <td>7.161821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.292900</td>\n",
       "      <td>7.054526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.172300</td>\n",
       "      <td>6.969343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.086100</td>\n",
       "      <td>6.912333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.021000</td>\n",
       "      <td>6.870550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.975100</td>\n",
       "      <td>6.840890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.933100</td>\n",
       "      <td>6.821639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.921800</td>\n",
       "      <td>6.812575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.904000</td>\n",
       "      <td>6.804057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.899000</td>\n",
       "      <td>6.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.889300</td>\n",
       "      <td>6.801312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2409431040000\n",
      "Human Readable: 2,409,431,040,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.706872463226318, 'eval_runtime': 3.4749, 'eval_samples_per_second': 68.491, 'eval_steps_per_second': 34.245, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1,186,176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 352,256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2752' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2752/3440 12:11 < 03:02, 3.76 it/s, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.801200</td>\n",
       "      <td>13.069245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.997000</td>\n",
       "      <td>8.187204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.257200</td>\n",
       "      <td>6.790093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.348500</td>\n",
       "      <td>6.370649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.947900</td>\n",
       "      <td>5.996587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.720100</td>\n",
       "      <td>5.856564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.570800</td>\n",
       "      <td>5.781667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.461800</td>\n",
       "      <td>5.699616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.377400</td>\n",
       "      <td>5.667982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.307400</td>\n",
       "      <td>5.612002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.244400</td>\n",
       "      <td>5.586812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.194400</td>\n",
       "      <td>5.570797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.154200</td>\n",
       "      <td>5.563239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.115800</td>\n",
       "      <td>5.549538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.085700</td>\n",
       "      <td>5.536205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.063100</td>\n",
       "      <td>5.536566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 40112410853376\n",
      "Human Readable: 40,112,410,853,376\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.4911789894104, 'eval_runtime': 11.6071, 'eval_samples_per_second': 20.505, 'eval_steps_per_second': 10.252, 'epoch': 16.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n",
      "NON EMBEDDING PARAMETERS: 4,737,536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 980,992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9580' max='9580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9580/9580 1:20:46, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.586800</td>\n",
       "      <td>8.529173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.023900</td>\n",
       "      <td>6.534838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.028900</td>\n",
       "      <td>5.972638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.679800</td>\n",
       "      <td>5.623368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.478000</td>\n",
       "      <td>5.499987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.341200</td>\n",
       "      <td>5.382205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.222700</td>\n",
       "      <td>5.247132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.116000</td>\n",
       "      <td>5.192339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.028800</td>\n",
       "      <td>5.137402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>5.093064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.883000</td>\n",
       "      <td>5.041945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.824900</td>\n",
       "      <td>5.014031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.776100</td>\n",
       "      <td>4.992816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.735400</td>\n",
       "      <td>4.978132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.700700</td>\n",
       "      <td>4.965396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.673800</td>\n",
       "      <td>4.957792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.652800</td>\n",
       "      <td>4.953721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.638900</td>\n",
       "      <td>4.950713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.630000</td>\n",
       "      <td>4.948266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.624600</td>\n",
       "      <td>4.947930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 557698189885440\n",
      "Human Readable: 557,698,189,885,440\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.893099308013916, 'eval_runtime': 24.2199, 'eval_samples_per_second': 9.827, 'eval_steps_per_second': 4.913, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 256, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 layers\n",
      "NON EMBEDDING PARAMETERS: 10,683,520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1,789,952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17480' max='17480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17480/17480 3:27:27, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.208200</td>\n",
       "      <td>7.186676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.427100</td>\n",
       "      <td>5.967497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.796100</td>\n",
       "      <td>5.667115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.582400</td>\n",
       "      <td>5.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.424700</td>\n",
       "      <td>5.386971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.299400</td>\n",
       "      <td>5.283226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.191800</td>\n",
       "      <td>5.203666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.106700</td>\n",
       "      <td>5.139759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.032300</td>\n",
       "      <td>5.097339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.967400</td>\n",
       "      <td>5.050296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.912800</td>\n",
       "      <td>5.018058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.863600</td>\n",
       "      <td>4.993073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.822300</td>\n",
       "      <td>4.964553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.787300</td>\n",
       "      <td>4.945002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.755400</td>\n",
       "      <td>4.935725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.730600</td>\n",
       "      <td>4.923713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.711000</td>\n",
       "      <td>4.917772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.697000</td>\n",
       "      <td>4.912977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.688300</td>\n",
       "      <td>4.911886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.683700</td>\n",
       "      <td>4.911436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 2294758558924800\n",
      "Human Readable: 2,294,758,558,924,800\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.83888578414917, 'eval_runtime': 35.3859, 'eval_samples_per_second': 6.726, 'eval_steps_per_second': 3.363, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 320, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 layers\n",
      "NON EMBEDDING PARAMETERS: 30,576,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 3,897,344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15224' max='38060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15224/38060 4:35:12 < 6:52:51, 0.92 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.618300</td>\n",
       "      <td>6.561160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.440300</td>\n",
       "      <td>6.310968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.264800</td>\n",
       "      <td>6.277349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.204100</td>\n",
       "      <td>6.186130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.176900</td>\n",
       "      <td>6.162142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.156900</td>\n",
       "      <td>6.139637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.144800</td>\n",
       "      <td>6.137690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.132500</td>\n",
       "      <td>6.152413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 5719929126912000\n",
      "Human Readable: 5,719,929,126,912,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.087133407592773, 'eval_runtime': 49.7891, 'eval_samples_per_second': 4.78, 'eval_steps_per_second': 2.39, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 448, rnn = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # to count tokens, comes from https://huggingface.co/docs/tokenizers/components\n",
    "# whitespace_regex = re.compile(\"\\w+|[^\\w\\s]+\")\n",
    "\n",
    "# # get number of tokens\n",
    "# total_tokens = 0\n",
    "# for row in raw_datasets[\"train\"][\"text\"]:\n",
    "#     total_tokens += len((whitespace_regex.split(row)))\n",
    "# total_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
