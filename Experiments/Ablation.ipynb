{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import leap\n", "from leap import LeapForCausalLM, LeapConfig\n", "from lstm import LstmForCausalLM\n", "from transformers import (PreTrainedTokenizerFast, TrainingArguments,\n", "                          Trainer, default_data_collator,\n", "                          GPT2Config, GPT2LMHeadModel)\n", "\n", "from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n", "from torch.utils.data import Subset\n", "\n", "# word level tokenizer as per wikitext modeling\n", "from tokenizers import Tokenizer\n", "from tokenizers.models import WordLevel\n", "from tokenizers.pre_tokenizers import Whitespace\n", "from tokenizers.trainers import WordLevelTrainer\n", "\n", "import math\n", "import copy\n", "from itertools import chain\n", "\n", "import matplotlib.pyplot as plt\n", "from scipy.optimize import curve_fit\n", "import numpy as np\n", "\n", "import logging\n", "logging.disable(logging.INFO)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# globals\n", "param_data_ratio = 1 / 10\n", "seq_len = 2048\n", "\n", "# hyperparameters\n", "training_args = TrainingArguments(\n", "    output_dir = \"./results\",\n", "    logging_strategy = \"steps\",\n", "    evaluation_strategy = \"steps\",\n", "    logging_steps = 1000,\n", "    report_to = \"none\",\n", "    learning_rate = 1e-3,\n", "    lr_scheduler_type = \"cosine\",\n", "    warmup_ratio = .05,\n", "    num_train_epochs = 1,\n", "    per_device_train_batch_size = 12,\n", "    per_device_eval_batch_size = 12,\n", "    max_grad_norm = 1,\n", "    fp16 = True,\n", "    log_level = 'error'\n", ")\n", "\n", "# see appendix for creating this file\n", "lm_dataset = load_from_disk('8192_wikitext.dt')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## helper functions"], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def subset_data(dataset, num_parameters, param_data_ratio):\n", "    dataset = DatasetDict(copy.deepcopy(dataset))\n", "    subset_num_tokens = num_parameters / param_data_ratio\n", "    \n", "    global seq_len\n", "    num_rows = int(subset_num_tokens) // seq_len\n", "\n", "    training_set = dataset[\"train\"]\n", "    dataset[\"train\"] = Dataset.from_dict(training_set[:num_rows+1])\n", "    \n", "    real_num_tokens = len(dataset[\"train\"]) * seq_len\n", "    \n", "    dataset.set_format('pt')\n", "    return dataset\n", "\n", "def run_training(hidden_size, n_head = None, gpt = False):\n", "    # calculate number of layers needed based on levine 2020\n", "    n_layer = round((math.log(hidden_size) - 5.039) / 5.55e-2)\n", "    n_layer = max(1, n_layer)\n", "    \n", "    if gpt is True:\n", "        config = GPT2Config(\n", "            n_embd = hidden_size, n_layer = n_layer, n_head = n_head,\n", "            vocab_size = 8192, n_positions = seq_len,\n", "            initializer_range = 1 / hidden_size**.5,\n", "            resid_pdrop = 0, embd_pdrop = 0, attn_pdrop = 0 # no dropout bc one epoch\n", "        )\n", "        model = GPT2LMHeadModel(config)\n", "    else:\n", "        config = LeapConfig(\n", "            hidden_size = hidden_size, n_layer = n_layer, n_head = n_head,\n", "            vocab_size = 8192, n_positions = seq_len,\n", "            use_local_att = True, window_sizes = None, rescale = 10,\n", "            initializer_range = 1 / hidden_size**.5, hidden_dropout_prob = 0 # no dropout bc one epoch\n", "        )\n", "        model = LeapForCausalLM(config)\n", "\n", "    # get number of parameters\n", "    total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n", "    \n", "    # get rid of embedding parameters\n", "    token_embeddings = 8192 * hidden_size\n", "    position_embeddings = seq_len * hidden_size\n", "    non_embedding_parameters = total_parameters - token_embeddings - position_embeddings\n", "\n", "    # subset dataset using global lm_dataset\n", "    global lm_dataset\n", "    subset_datasets = subset_data(lm_dataset, non_embedding_parameters, param_data_ratio)\n", "\n", "    trainer = Trainer(\n", "        model=model,\n", "        args=training_args,\n", "        data_collator=default_data_collator,\n", "        train_dataset=subset_datasets[\"train\"],\n", "        eval_dataset=subset_datasets[\"validation\"],\n", "    )\n", "\n", "    trainer.train()\n", "    \n", "    best_valid_loss = trainer.evaluate()[\"eval_loss\"]\n", "\n", "    # save gpu memory\n", "    del trainer\n", "    del model\n", "    del subset_datasets\n", "    torch.cuda.empty_cache()\n", "    \n", "    return non_embedding_parameters, best_valid_loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# TRAINING FUNCTION"], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sizes = [\n", "    {\"hidden_size\": 64, \"n_head\": 1},\n", "    {\"hidden_size\": 128, \"n_head\": 2},\n", "    {\"hidden_size\": 160, \"n_head\": 2},\n", "    {\"hidden_size\": 176, \"n_head\": 2},\n", "    {\"hidden_size\": 192, \"n_head\": 3},\n", "    {\"hidden_size\": 224, \"n_head\": 4},\n", "    {\"hidden_size\": 256, \"n_head\": 4},\n", "]\n", "\n", "def powerlaw(n, n_c, a):\n", "    return (n_c / n)**a\n", "\n", "def try_scaling(gpt = False):\n", "    params = []\n", "    losses = []\n", "\n", "    for size in sizes:\n", "        param, loss = run_training(**size, gpt = gpt)\n", "        params.append(param)\n", "        losses.append(loss)\n", "    \n", "    # graphing and powerlaws \n", "    params = np.array(params, dtype = 'int64')\n", "    losses = np.array(losses, dtype = 'float64')\n", "    \n", "    plt.loglog()\n", "    plt.scatter(x = params, y = losses)\n", "    (n_c, a), _ = curve_fit(powerlaw, params, losses, maxfev=10000, p0 = np.array([9e13, .076]))\n", "    plt.plot(params, powerlaw(params, n_c, a), linestyle = '--')\n", "    plt.show()\n", "    \n", "    print(\"\\n===============RAW NUMBERS===============\\n\")\n", "    print(\"Parameters:\", list(params))\n", "    print(\"Losses:\", list(losses))\n", "    \n", "    print(\"\\n===============SCALING LAW===============\\n\")\n", "    print(f\"Constant factor N_c: {n_c:.0}, Exponent: {a:.3}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Ablations\n", "\n", "The idea here is instead of changing the source code in LEAP.py over and over again and then running personal experiments, that it makes much more sense to record this stuff in a notebook. Still it seems like a bad option to have to write a bunch of if statements about which little abalation to use. The solution, monkey patching! We will rewrite the LEAP forward function before each abalation test. An example is shown, and this notebook will be annotated"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## original forward function"], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def forward(self, q, f, k, v, attention_mask = None):        \n", "        batch_size, seq_len, hidden_size = v.shape\n", "        \n", "        # reshape for multihead formulation\n", "        q = q.reshape(batch_size, seq_len, self.n_head, self.head_size)\n", "        f = f.reshape(batch_size, seq_len, self.n_head, self.head_size)\n", "        k = k.reshape(batch_size, seq_len, self.n_head, self.head_size)\n", "        v = v.reshape(batch_size, seq_len, self.n_head, self.head_size)\n", "        \n", "        # unparameterized norming of vectors so dot products don't explode (also why it is after reshaping)\n", "        if self.rescale:\n", "            q = self.__real_norm(q)\n", "            f = self.__real_norm(f)\n", "            k = self.__real_norm(k)\n", "            v = self.__real_norm(v)\n", "            \n", "        # dropout regularization (keys don't need dropout as they are always dotted with a dropped out vector)\n", "        q = self.drop(q)\n", "        f = self.drop(f)\n", "        v = self.drop(v)\n", "\n", "        # manual \"matrix dot product\" for speed (in einsum notation \"bshe, bshe->bsh\") with scaling\n", "        focus_logits = (f * k).sum(dim = -1) * self.scaling_factor\n", "        \n", "        # apply dropout to logits so that all tokens will have a chance at getting focus\n", "        focus_logits = self.drop(focus_logits)\n", "        \n", "        # masking out pad tokens\n", "        if attention_mask is not None:\n", "            focus_logits += attention_mask\n", "        \n", "        # manual softmax within cumulative sum\n", "        focus_weights = torch.exp(focus_logits)\n", "        focus_weights = focus_weights.unsqueeze(-1)\n", "        \n", "        # normalization term for softmax\n", "        cumulative_weights = torch.cumsum(focus_weights, dim = 1)\n", "        cumulative_weights = cumulative_weights - self.__window_align(cumulative_weights)\n", "        \n", "        focused_k = self.__w_focus(focus_weights, cumulative_weights, k)\n", "        focused_v = self.__w_focus(focus_weights, cumulative_weights, v)\n", "        \n", "        # querying by measuring dot product alignment (with scaling)\n", "        alignment = torch.sigmoid((q * focused_k).sum(dim = -1) * self.scaling_factor)\n", "        attention = alignment.unsqueeze(-1) * focused_v\n", "        \n", "        # concat heads\n", "        attention = focused_v.reshape(batch_size, seq_len, hidden_size)\n", "        \n", "        return attention"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [21/21 00:00, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [81/81 00:03, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [126/126 00:06, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='304' max='304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [304/304 00:20, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='723' max='723' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [723/723 01:16, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='1721' max='1721' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [1721/1721 05:10, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1000</td>\n", "      <td>4.861500</td>\n", "      <td>4.326162</td>\n", "    </tr>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='2889' max='2889' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [2889/2889 11:30, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1000</td>\n", "      <td>4.835300</td>\n", "      <td>4.250451</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2000</td>\n", "      <td>4.061200</td>\n", "      <td>3.938624</td>\n", "    </tr>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:01]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stderr", "output_type": "stream", "text": ["<ipython-input-29-795d6ed49ad2>:12: RuntimeWarning: invalid value encountered in power\n", "  return (n_c / n)**a\n"]}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["\n", "===============RAW NUMBERS===============\n", "\n", "Parameters: [49856, 198016, 308960, 746944, 1776768, 4229344, 7099136]\n", "Losses: [8.088715553283691, 5.93641996383667, 5.764010429382324, 5.351748943328857, 4.7581892013549805, 4.203468322753906, 3.8781819343566895]\n", "\n", "===============SCALING LAW===============\n", "\n", "Constant factor N_c: 8e+10, Exponent: 0.144\n"]}], "source": ["try_scaling()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## monkey patched"], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def forward(self, q, f, k, v, attention_mask = None):        \n", "    print(\"we abalate the entirety of LEAP here :)\", end = '\\r')\n", "    return v\n", "\n", "leap.MultiheadLeap.forward = forward"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [21/21 00:00, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [81/81 00:03, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [126/126 00:05, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='304' max='304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [304/304 00:14, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='723' max='723' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [723/723 00:44, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='1721' max='1721' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [1721/1721 02:35, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1000</td>\n", "      <td>5.141800</td>\n", "      <td>4.884054</td>\n", "    </tr>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"name": "stderr", "output_type": "stream", "text": ["C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n", "  warnings.warn(\n"]}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='2889' max='2889' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [2889/2889 05:50, Epoch 1/1]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>1000</td>\n", "      <td>5.146100</td>\n", "      <td>4.880362</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2000</td>\n", "      <td>4.795100</td>\n", "      <td>4.791285</td>\n", "    </tr>\n", "  </tbody>\n", "</table><p>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"data": {"text/html": ["\n", "    <div>\n", "      \n", "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [18/18 00:00]\n", "    </div>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["we abalate the entirety of LEAP here :)\r"]}, {"name": "stderr", "output_type": "stream", "text": ["<ipython-input-29-795d6ed49ad2>:12: RuntimeWarning: invalid value encountered in power\n", "  return (n_c / n)**a\n"]}, {"data": {"image/png": "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\n", "text/plain": ["<Figure size 432x288 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": ["\n", "===============RAW NUMBERS===============\n", "\n", "Parameters: [49856, 198016, 308960, 746944, 1776768, 4229344, 7099136]\n", "Losses: [8.534381866455078, 5.9223833084106445, 5.720045566558838, 5.328155994415283, 5.014240741729736, 4.841979026794434, 4.766572952270508]\n", "\n", "===============SCALING LAW===============\n", "\n", "Constant factor N_c: 1e+12, Exponent: 0.121\n"]}], "source": ["try_scaling()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Appendix"], "execution_count": null}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Found cached dataset wikitext (C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "9b7b26c228b8421186c5cb88a1c78391", "version_major": 2, "version_minor": 0}, "text/plain": ["  0%|          | 0/3 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"name": "stderr", "output_type": "stream", "text": ["Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-a2031eb206d20f87.arrow\n", "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-8f3dd2e5d5819fe2.arrow\n", "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-f4668efef485cbea.arrow\n", "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-c465af52033c5930.arrow\n", "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-f4bd6838579180b3.arrow\n", "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-ae2831909d2c4b02.arrow\n"]}], "source": ["raw_datasets = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n", "\n", "# make a word level tokenizer\n", "tokenizer = Tokenizer(WordLevel(unk_token=\"<unk>\"))\n", "tokenizer.pre_tokenizer = Whitespace()\n", "tokenizer.enable_padding(pad_id = 0, pad_token = \"<pad>\")\n", "# no post processing\n", "\n", "# only use vocab size of 8192 for reasonable speed/memory\n", "token_trainer = WordLevelTrainer(vocab_size = 8191, # -1 for pad token\n", "                                 special_tokens = [\"<unk>\"])\n", "\n", "def batch_iterator(batch_size=10000):\n", "    text = raw_datasets[\"train\"]['text']\n", "    for i in range(0, len(text), batch_size):\n", "        yield text[i : i + batch_size]\n", "\n", "tokenizer.train_from_iterator(batch_iterator(),\n", "                              trainer = token_trainer,\n", "                              length = len(raw_datasets[\"train\"][\"text\"]))\n", "tokenizer = PreTrainedTokenizerFast(tokenizer_object = tokenizer, pad_token = \"<pad>\")\n", "\n", "# tokenized the dataset\n", "def tokenize_function(examples):\n", "    output = tokenizer(examples[\"text\"])\n", "    return output\n", "\n", "# tokenize dataset\n", "tokenized_datasets = raw_datasets.map(\n", "    tokenize_function,\n", "    batched = True,\n", "    remove_columns = \"text\",\n", "    desc = f\"tokenize dataset\",\n", "    load_from_cache_file = True\n", ")\n", "\n", "def group_texts(examples):\n", "    # Concatenate all texts\n", "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n", "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n", "\n", "    # Split by chunks of max_len\n", "    result = {\n", "        k: [t[i : i + seq_len] for i in range(0, total_length, seq_len)]\n", "        for k, t in concatenated_examples.items()\n", "    }\n", "    \n", "    # for language modeling, inputs are labels (they will be shifted inside the model)\n", "    result[\"labels\"] = result[\"input_ids\"].copy()\n", "    \n", "    # pad last block with 0\n", "    last_ids = result[\"input_ids\"][-1]\n", "    diff = seq_len - len(last_ids)\n", "    result[\"input_ids\"][-1] = last_ids + [0 for _ in range(diff)]\n", "    \n", "    # set attention mask to mask out these tokens\n", "    result[\"attention_mask\"][-1] = result[\"attention_mask\"][-1] + [0 for _ in range(diff)]\n", "    \n", "    # set pad labels to -100 so they will be ignored by CrossEntropyLoss\n", "    result[\"labels\"][-1] = result[\"labels\"][-1] + [-100 for _ in range(diff)]\n", "    return result\n", "\n", "lm_dataset = tokenized_datasets.map(\n", "    group_texts,\n", "    batched = True,\n", "    batch_size = 10000,\n", "    desc = f\"Grouping texts in chunks of {seq_len}\",\n", "    load_from_cache_file = True\n", ")\n", "\n", "lm_dataset = lm_dataset.remove_columns([\"token_type_ids\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["8192"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["len(tokenizer) + 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}