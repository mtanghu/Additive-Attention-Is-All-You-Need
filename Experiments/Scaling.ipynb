{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from leap import LeapForCausalLM, LeapConfig\n",
    "from lstm import LstmForCausalLM\n",
    "from transformers import (PreTrainedTokenizerFast, TrainingArguments,\n",
    "                          Trainer, default_data_collator,\n",
    "                          GPT2Config, GPT2LMHeadModel)\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# word level tokenizer as per wikitext modeling\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf164de8b8cb4644812d93481e70e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# globals\n",
    "raw_datasets = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "total_train_tokens = 105268829 # see appendix at the end of notebook\n",
    "max_num_params = 69308416\n",
    "param_data_ratio = max_num_params**.74 / total_train_tokens\n",
    "seq_len = 1024\n",
    "subset_datasets = raw_datasets\n",
    "\n",
    "# hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    logging_strategy = \"steps\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    logging_steps = 500,\n",
    "    save_steps = 500,\n",
    "    report_to = \"none\",\n",
    "    learning_rate = 5e-4,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = .05,\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    max_grad_norm = 1,\n",
    "    fp16 = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-a2031eb206d20f87.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-8f3dd2e5d5819fe2.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-f4668efef485cbea.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-9004e9678f0a1614.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-d189dc21c09aa046.arrow\n",
      "Loading cached processed dataset at C:/Users/micha/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\\cache-50bce12b611e856c.arrow\n"
     ]
    }
   ],
   "source": [
    "# make a word level tokenizer\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.enable_padding(pad_id = 0, pad_token = \"<pad>\")\n",
    "# no post processing\n",
    "\n",
    "# only use vocab size of 8192 for reasonable speed/memory\n",
    "token_trainer = WordLevelTrainer(vocab_size = 8191, # -1 for pad token\n",
    "                                 special_tokens = [\"<unk>\"])\n",
    "\n",
    "def batch_iterator(batch_size=10000):\n",
    "    text = raw_datasets[\"train\"]['text']\n",
    "    for i in range(0, len(text), batch_size):\n",
    "        yield text[i : i + batch_size]\n",
    "\n",
    "tokenizer.train_from_iterator(batch_iterator(),\n",
    "                              trainer = token_trainer,\n",
    "                              length = len(raw_datasets[\"train\"][\"text\"]))\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object = tokenizer, pad_token = \"<pad>\")\n",
    "\n",
    "# tokenized the dataset\n",
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples[\"text\"])\n",
    "    return output\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched = True,\n",
    "    remove_columns = \"text\",\n",
    "    desc = f\"tokenize dataset\",\n",
    "    load_from_cache_file = True\n",
    ")\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + seq_len] for i in range(0, total_length, seq_len)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    # for language modeling, inputs are labels (they will be shifted inside the model)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    \n",
    "    # pad last block with 0\n",
    "    last_ids = result[\"input_ids\"][-1]\n",
    "    diff = seq_len - len(last_ids)\n",
    "    result[\"input_ids\"][-1] = last_ids + [0 for _ in range(diff)]\n",
    "    \n",
    "    # set attention mask to mask out these tokens\n",
    "    result[\"attention_mask\"][-1] = result[\"attention_mask\"][-1] + [0 for _ in range(diff)]\n",
    "    \n",
    "    # set pad labels to -100 so they will be ignored by CrossEntropyLoss\n",
    "    result[\"labels\"][-1] = result[\"labels\"][-1] + [-100 for _ in range(diff)]\n",
    "    return result\n",
    "\n",
    "# set globally block size for group texts function\n",
    "lm_dataset = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched = True,\n",
    "    batch_size = 10000,\n",
    "    desc = f\"Grouping texts in chunks of {seq_len}\",\n",
    "    load_from_cache_file = True\n",
    ")\n",
    "\n",
    "lm_dataset = lm_dataset.remove_columns([\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(dataset, num_parameters, param_data_ratio):\n",
    "    dataset = DatasetDict(copy.deepcopy(dataset))\n",
    "    subset_num_tokens = num_parameters**.74 / param_data_ratio\n",
    "    \n",
    "    global seq_len\n",
    "    num_rows = int(subset_num_tokens) // seq_len\n",
    "\n",
    "    training_set = dataset[\"train\"]\n",
    "    dataset[\"train\"] = Dataset.from_dict(training_set[:num_rows+1])\n",
    "    \n",
    "    real_num_tokens = len(dataset[\"train\"]) * seq_len\n",
    "    print(f'NUMBER OF TOKENS: {real_num_tokens}, with commas {real_num_tokens:,}')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(hidden_size, n_head = None, gpt = False, rnn = False):\n",
    "    # calculate number of layers needed based on levine 2020\n",
    "    n_layer = round((math.log(hidden_size) - 5.039) / 5.55e-2)\n",
    "    n_layer = max(1, n_layer)\n",
    "    print(f'Using {n_layer} layers')\n",
    "    \n",
    "    # get number of parameters\n",
    "    if gpt is True:\n",
    "        config = GPT2Config(\n",
    "            n_embd = hidden_size, n_layer = n_layer,\n",
    "            n_head = 1, vocab_size = 0, n_positions = 0\n",
    "        )\n",
    "        model = GPT2LMHeadModel(config)\n",
    "    elif rnn is True:\n",
    "        model = LstmForCausalLM(\n",
    "            hidden_size = hidden_size,\n",
    "            n_layer = n_layer,\n",
    "            vocab_size = 0\n",
    "        )\n",
    "    else:\n",
    "        config = LeapConfig(\n",
    "            hidden_size = hidden_size, n_layer = n_layer,\n",
    "            n_head = n_head, vocab_size = 0, n_positions = 0\n",
    "        )\n",
    "        model = LeapForCausalLM(config)\n",
    "\n",
    "    non_embedding_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'NON EMBEDDING PARAMETERS: {non_embedding_parameters}, with commas {non_embedding_parameters:,}')\n",
    "\n",
    "    # subset dataset using global lm_dataset\n",
    "    global lm_dataset\n",
    "    subset_datasets = subset_data(lm_dataset, non_embedding_parameters, param_data_ratio)\n",
    "\n",
    "    if gpt is True:\n",
    "        config = GPT2Config(\n",
    "            n_embd = hidden_size, n_layer = n_layer, n_head = n_head,\n",
    "            vocab_size = len(tokenizer) + 1, n_positions = seq_len,\n",
    "            initializer_range = 1 / hidden_size**.5,\n",
    "            resid_pdrop = 0, embd_pdrop = 0, attn_pdrop = 0 # no dropout bc one epoch\n",
    "        )\n",
    "        model = GPT2LMHeadModel(config)\n",
    "    elif rnn is True:\n",
    "        model = LstmForCausalLM(\n",
    "            hidden_size = hidden_size,\n",
    "            n_layer = n_layer,\n",
    "            vocab_size = len(tokenizer) + 1,\n",
    "            hidden_dropout_prob = 0\n",
    "        )\n",
    "    else:\n",
    "        config = LeapConfig(\n",
    "            hidden_size = hidden_size, n_layer = n_layer, n_head = n_head,\n",
    "            vocab_size = len(tokenizer) + 1, n_positions = seq_len,\n",
    "            use_local_att = True, window_sizes = None, rescale = 10,\n",
    "            initializer_range = 1 / hidden_size**.5, hidden_dropout_prob = 0 # no dropout bc one epoch\n",
    "        )\n",
    "        model = LeapForCausalLM(config)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=default_data_collator,\n",
    "        train_dataset=subset_datasets[\"train\"],\n",
    "        eval_dataset=subset_datasets[\"validation\"],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\n===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\\n\")\n",
    "    print(f'Numeric form: {int(trainer.state.total_flos)}\\nHuman Readable: {int(trainer.state.total_flos):,}')\n",
    "\n",
    "    print(\"\\n===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\\n\")\n",
    "    print(trainer.evaluate(subset_datasets[\"test\"]))\n",
    "\n",
    "    # save gpu memory\n",
    "    del trainer\n",
    "    del model\n",
    "    del subset_datasets\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 TRAINING\n",
    "Each run is done seperately in it's own cell just for easy viewing of logs and in case something goes wrong (OOM errors or training issues). Note that the learning rate had to be lowered from 1e-3 to 5e-4 because gpt2 wasn't converging on the largest test and all tests redone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 50112, with commas 50,112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 499712, with commas 499,712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [244/244 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 150249406464\n",
      "Human Readable: 150,249,406,464\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.038037300109863, 'eval_runtime': 0.7756, 'eval_samples_per_second': 306.864, 'eval_steps_per_second': 153.432, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, n_head = 1, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 198528, with commas 198,528\n",
      "NUMBER OF TOKENS: 1382400, with commas 1,382,400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.923600</td>\n",
       "      <td>5.628588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1646670643200\n",
      "Human Readable: 1,646,670,643,200\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.565395355224609, 'eval_runtime': 0.7777, 'eval_samples_per_second': 306.029, 'eval_steps_per_second': 153.015, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, n_head = 2, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 309600, with commas 309,600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1921024, with commas 1,921,024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [938/938 00:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.871900</td>\n",
       "      <td>5.523679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 3568494182400\n",
      "Human Readable: 3,568,494,182,400\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.4598236083984375, 'eval_runtime': 0.7884, 'eval_samples_per_second': 301.859, 'eval_steps_per_second': 150.93, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, n_head = 2, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1779840, with commas 1,779,840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 7005184, with commas 7,005,184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3421' max='3421' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3421/3421 02:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.880200</td>\n",
       "      <td>5.375783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.169800</td>\n",
       "      <td>5.121512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.002600</td>\n",
       "      <td>4.990281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.882700</td>\n",
       "      <td>4.893657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.810200</td>\n",
       "      <td>4.835835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.766800</td>\n",
       "      <td>4.809031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 74808640143360\n",
      "Human Readable: 74,808,640,143,360\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.734671592712402, 'eval_runtime': 1.4655, 'eval_samples_per_second': 162.4, 'eval_steps_per_second': 81.2, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, n_head = 3, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 layers\n",
      "NON EMBEDDING PARAMETERS: 4235616, with commas 4,235,616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 13305856, with commas 13,305,856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6497' max='6497' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6497/6497 08:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.934400</td>\n",
       "      <td>5.370236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.153100</td>\n",
       "      <td>5.088532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.973100</td>\n",
       "      <td>4.937986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.867700</td>\n",
       "      <td>4.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.770800</td>\n",
       "      <td>4.753085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.680800</td>\n",
       "      <td>4.669009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.598300</td>\n",
       "      <td>4.597792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.553300</td>\n",
       "      <td>4.530530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.474900</td>\n",
       "      <td>4.478220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.430700</td>\n",
       "      <td>4.430018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.386800</td>\n",
       "      <td>4.401743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.373100</td>\n",
       "      <td>4.389958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 338150979403776\n",
      "Human Readable: 338,150,979,403,776\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.317898750305176, 'eval_runtime': 2.5658, 'eval_samples_per_second': 92.757, 'eval_steps_per_second': 46.379, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 224, n_head = 4, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n",
      "NON EMBEDDING PARAMETERS: 7108352, with commas 7,108,352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 19518464, with commas 19,518,464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9531' max='9531' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9531/9531 16:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.947600</td>\n",
       "      <td>5.404133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.195800</td>\n",
       "      <td>5.097146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.990100</td>\n",
       "      <td>4.945464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.864600</td>\n",
       "      <td>4.837646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.778900</td>\n",
       "      <td>4.752940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.674500</td>\n",
       "      <td>4.662962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.593700</td>\n",
       "      <td>4.575736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.516000</td>\n",
       "      <td>4.498229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.429400</td>\n",
       "      <td>4.408222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.371200</td>\n",
       "      <td>4.340597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.285400</td>\n",
       "      <td>4.268012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.234500</td>\n",
       "      <td>4.210172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.177500</td>\n",
       "      <td>4.160933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.130300</td>\n",
       "      <td>4.124665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.096200</td>\n",
       "      <td>4.097829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.072500</td>\n",
       "      <td>4.076357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.048800</td>\n",
       "      <td>4.063325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.041900</td>\n",
       "      <td>4.057476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.038200</td>\n",
       "      <td>4.056235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 832464675667968\n",
      "Human Readable: 832,464,675,667,968\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.996950387954712, 'eval_runtime': 3.2961, 'eval_samples_per_second': 72.207, 'eval_steps_per_second': 36.103, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 256, n_head = 4, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 16029120, with commas 16,029,120\n",
      "NUMBER OF TOKENS: 35624960, with commas 35,624,960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17395' max='17395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17395/17395 47:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.984400</td>\n",
       "      <td>5.439550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.209500</td>\n",
       "      <td>5.141995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.006600</td>\n",
       "      <td>4.971425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.885900</td>\n",
       "      <td>4.854750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.795700</td>\n",
       "      <td>4.794035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.707500</td>\n",
       "      <td>4.697477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.610100</td>\n",
       "      <td>4.607020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.541200</td>\n",
       "      <td>4.522990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.468200</td>\n",
       "      <td>4.428399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.380500</td>\n",
       "      <td>4.349230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.298400</td>\n",
       "      <td>4.272038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.217200</td>\n",
       "      <td>4.199662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>4.131761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.102500</td>\n",
       "      <td>4.064461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.055600</td>\n",
       "      <td>4.037722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.000800</td>\n",
       "      <td>3.973632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.942400</td>\n",
       "      <td>3.937718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.922100</td>\n",
       "      <td>3.903038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.886800</td>\n",
       "      <td>3.869648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.849700</td>\n",
       "      <td>3.840024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.822400</td>\n",
       "      <td>3.817307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.803300</td>\n",
       "      <td>3.784608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.764600</td>\n",
       "      <td>3.763017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.737400</td>\n",
       "      <td>3.743133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.744300</td>\n",
       "      <td>3.722451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.727500</td>\n",
       "      <td>3.707827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.700900</td>\n",
       "      <td>3.692480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.708200</td>\n",
       "      <td>3.680235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.688100</td>\n",
       "      <td>3.671085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.672000</td>\n",
       "      <td>3.661979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.666500</td>\n",
       "      <td>3.656528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.666600</td>\n",
       "      <td>3.652829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.657500</td>\n",
       "      <td>3.650912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.651300</td>\n",
       "      <td>3.649998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 3426220553011200\n",
      "Human Readable: 3,426,220,553,011,200\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.617107391357422, 'eval_runtime': 5.4826, 'eval_samples_per_second': 43.41, 'eval_steps_per_second': 21.705, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 320, n_head = 5, gpt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 layers\n",
      "NON EMBEDDING PARAMETERS: 45872064, with commas 45,872,064\n",
      "NUMBER OF TOKENS: 77564928, with commas 77,564,928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37874' max='37874' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37874/37874 3:13:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.031200</td>\n",
       "      <td>5.466364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.266000</td>\n",
       "      <td>5.190466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.057200</td>\n",
       "      <td>5.023293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.956300</td>\n",
       "      <td>4.945972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.876700</td>\n",
       "      <td>4.826606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.765500</td>\n",
       "      <td>4.740273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.697000</td>\n",
       "      <td>4.677341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.633700</td>\n",
       "      <td>4.622077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.576200</td>\n",
       "      <td>4.559217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.496700</td>\n",
       "      <td>4.482879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.422400</td>\n",
       "      <td>4.392384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.337600</td>\n",
       "      <td>4.318099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.261900</td>\n",
       "      <td>4.227516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.190200</td>\n",
       "      <td>4.164449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.129900</td>\n",
       "      <td>4.111277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.064000</td>\n",
       "      <td>4.042594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.013800</td>\n",
       "      <td>4.008232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.979400</td>\n",
       "      <td>3.946411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.935200</td>\n",
       "      <td>3.904753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.874500</td>\n",
       "      <td>3.864056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.869000</td>\n",
       "      <td>3.833820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.817700</td>\n",
       "      <td>3.811317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.801900</td>\n",
       "      <td>3.776865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.765500</td>\n",
       "      <td>3.757130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.744700</td>\n",
       "      <td>3.723871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.713200</td>\n",
       "      <td>3.698801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.704400</td>\n",
       "      <td>3.671619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.666000</td>\n",
       "      <td>3.658937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.656400</td>\n",
       "      <td>3.630566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.642700</td>\n",
       "      <td>3.610764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.611700</td>\n",
       "      <td>3.593423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.588100</td>\n",
       "      <td>3.575385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.582500</td>\n",
       "      <td>3.557119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.567900</td>\n",
       "      <td>3.548158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>3.560600</td>\n",
       "      <td>3.526461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.539900</td>\n",
       "      <td>3.509079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>3.509500</td>\n",
       "      <td>3.496561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.483500</td>\n",
       "      <td>3.476451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>3.512000</td>\n",
       "      <td>3.465210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.476600</td>\n",
       "      <td>3.456838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>3.465200</td>\n",
       "      <td>3.439033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.451200</td>\n",
       "      <td>3.428487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>3.420300</td>\n",
       "      <td>3.414819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.434800</td>\n",
       "      <td>3.405709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>3.432900</td>\n",
       "      <td>3.398905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.416900</td>\n",
       "      <td>3.386419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.399400</td>\n",
       "      <td>3.379016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.410700</td>\n",
       "      <td>3.365874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>3.390200</td>\n",
       "      <td>3.355592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.374300</td>\n",
       "      <td>3.346776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>3.350300</td>\n",
       "      <td>3.336448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.351100</td>\n",
       "      <td>3.330409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>3.344500</td>\n",
       "      <td>3.323724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.331900</td>\n",
       "      <td>3.315015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>3.339600</td>\n",
       "      <td>3.307005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>3.331500</td>\n",
       "      <td>3.298585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>3.307800</td>\n",
       "      <td>3.293266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>3.314400</td>\n",
       "      <td>3.288413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>3.315800</td>\n",
       "      <td>3.282645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.297300</td>\n",
       "      <td>3.277511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>3.313600</td>\n",
       "      <td>3.272749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>3.299000</td>\n",
       "      <td>3.268836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>3.295300</td>\n",
       "      <td>3.265192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>3.286600</td>\n",
       "      <td>3.260826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>3.287600</td>\n",
       "      <td>3.257252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>3.270400</td>\n",
       "      <td>3.254601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>3.269800</td>\n",
       "      <td>3.252039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>3.258300</td>\n",
       "      <td>3.250439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>3.281200</td>\n",
       "      <td>3.248230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>3.263900</td>\n",
       "      <td>3.247029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>3.277000</td>\n",
       "      <td>3.245785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>3.286500</td>\n",
       "      <td>3.245169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>3.263700</td>\n",
       "      <td>3.244645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>3.272700</td>\n",
       "      <td>3.244446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>3.272300</td>\n",
       "      <td>3.244391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 21348380048228352\n",
      "Human Readable: 21,348,380,048,228,352\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2382781505584717, 'eval_runtime': 10.8531, 'eval_samples_per_second': 21.929, 'eval_steps_per_second': 10.965, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 448, n_head = 7, gpt = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAP TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 49856, with commas 49,856\n",
      "NUMBER OF TOKENS: 497664, with commas 497,664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='243' max='243' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [243/243 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 148869218304\n",
      "Human Readable: 148,869,218,304\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.114893913269043, 'eval_runtime': 0.8957, 'eval_samples_per_second': 265.72, 'eval_steps_per_second': 132.86, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, n_head = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 198016, with commas 198,016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1380352, with commas 1,380,352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='674' max='674' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [674/674 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.107800</td>\n",
       "      <td>5.784122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1639990689792\n",
      "Human Readable: 1,639,990,689,792\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.721367835998535, 'eval_runtime': 0.8224, 'eval_samples_per_second': 289.388, 'eval_steps_per_second': 144.694, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, n_head = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 308960, with commas 308,960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\micha\\desktop\\leap\\src\\leap\\LEAP.py:200: UserWarning: Using a hidden_size-to-head ratio of greater than 64 is not ideal as LEAP uses a simplified form of attention that relies on having many heads\n",
      "  warnings.warn(\"Using a hidden_size-to-head ratio of greater than 64 is not ideal as\"\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1917952, with commas 1,917,952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937' max='937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937/937 00:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.025500</td>\n",
       "      <td>5.665014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 3555422699520\n",
      "Human Readable: 3,555,422,699,520\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.601402282714844, 'eval_runtime': 0.8223, 'eval_samples_per_second': 289.432, 'eval_steps_per_second': 144.716, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, n_head = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1776768, with commas 1,776,768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 6995968, with commas 6,995,968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3416' max='3416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3416/3416 02:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.088100</td>\n",
       "      <td>5.521639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.237200</td>\n",
       "      <td>5.147675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.968400</td>\n",
       "      <td>4.943083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.832500</td>\n",
       "      <td>4.823637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.733700</td>\n",
       "      <td>4.751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.679500</td>\n",
       "      <td>4.720037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 74581272428544\n",
      "Human Readable: 74,581,272,428,544\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.645600318908691, 'eval_runtime': 1.5258, 'eval_samples_per_second': 155.988, 'eval_steps_per_second': 77.994, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, n_head = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 layers\n",
      "NON EMBEDDING PARAMETERS: 4229344, with commas 4,229,344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 13291520, with commas 13,291,520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6490' max='6490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6490/6490 07:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.155500</td>\n",
       "      <td>5.549298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.256500</td>\n",
       "      <td>5.126582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.980900</td>\n",
       "      <td>4.891197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.780600</td>\n",
       "      <td>4.744344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.655000</td>\n",
       "      <td>4.643302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.566100</td>\n",
       "      <td>4.545161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.485700</td>\n",
       "      <td>4.473008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.426700</td>\n",
       "      <td>4.422051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.375600</td>\n",
       "      <td>4.377839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.333000</td>\n",
       "      <td>4.350260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.311200</td>\n",
       "      <td>4.325484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.304700</td>\n",
       "      <td>4.317365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 337286462177280\n",
      "Human Readable: 337,286,462,177,280\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.252130031585693, 'eval_runtime': 2.175, 'eval_samples_per_second': 109.426, 'eval_steps_per_second': 54.713, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 224, n_head = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n",
      "NON EMBEDDING PARAMETERS: 7099136, with commas 7,099,136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 19499008, with commas 19,499,008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9521' max='9521' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9521/9521 12:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.206400</td>\n",
       "      <td>5.578196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.279000</td>\n",
       "      <td>5.132071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.963200</td>\n",
       "      <td>4.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.777000</td>\n",
       "      <td>4.734221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.647800</td>\n",
       "      <td>4.624836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.525700</td>\n",
       "      <td>4.528377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.448600</td>\n",
       "      <td>4.438150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.387900</td>\n",
       "      <td>4.363996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.321800</td>\n",
       "      <td>4.311187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.262100</td>\n",
       "      <td>4.262807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.208100</td>\n",
       "      <td>4.213320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.181500</td>\n",
       "      <td>4.173914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.152800</td>\n",
       "      <td>4.142035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.116600</td>\n",
       "      <td>4.116820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.085100</td>\n",
       "      <td>4.090932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.062700</td>\n",
       "      <td>4.077952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.069900</td>\n",
       "      <td>4.070109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.049700</td>\n",
       "      <td>4.066248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.054400</td>\n",
       "      <td>4.065651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 830556657942528\n",
      "Human Readable: 830,556,657,942,528\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.007962703704834, 'eval_runtime': 2.5397, 'eval_samples_per_second': 93.712, 'eval_steps_per_second': 46.856, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 256, n_head = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13 layers\n",
      "NON EMBEDDING PARAMETERS: 16012480, with commas 16,012,480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 35598336, with commas 35,598,336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17382' max='17382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17382/17382 31:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.234500</td>\n",
       "      <td>5.631526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.340800</td>\n",
       "      <td>5.209981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.026300</td>\n",
       "      <td>4.926128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.796500</td>\n",
       "      <td>4.755405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>4.624541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.545600</td>\n",
       "      <td>4.527535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.442900</td>\n",
       "      <td>4.407835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.361500</td>\n",
       "      <td>4.329208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.290500</td>\n",
       "      <td>4.259641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.221200</td>\n",
       "      <td>4.212588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.160500</td>\n",
       "      <td>4.154064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.121700</td>\n",
       "      <td>4.108780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.068200</td>\n",
       "      <td>4.061160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.035200</td>\n",
       "      <td>4.023276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.001700</td>\n",
       "      <td>3.987423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.963800</td>\n",
       "      <td>3.963372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.942000</td>\n",
       "      <td>3.930539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.913100</td>\n",
       "      <td>3.905960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.890100</td>\n",
       "      <td>3.882147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.875300</td>\n",
       "      <td>3.854211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.841900</td>\n",
       "      <td>3.836088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>3.816982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.798400</td>\n",
       "      <td>3.799255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.781500</td>\n",
       "      <td>3.785859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.789600</td>\n",
       "      <td>3.772680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.772100</td>\n",
       "      <td>3.760230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.775800</td>\n",
       "      <td>3.747664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.755300</td>\n",
       "      <td>3.737905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.737700</td>\n",
       "      <td>3.730442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.716800</td>\n",
       "      <td>3.725642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.746700</td>\n",
       "      <td>3.720465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.707400</td>\n",
       "      <td>3.717974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.721600</td>\n",
       "      <td>3.716665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.710700</td>\n",
       "      <td>3.716166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 3420105859399680\n",
      "Human Readable: 3,420,105,859,399,680\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.68304181098938, 'eval_runtime': 3.6836, 'eval_samples_per_second': 64.61, 'eval_steps_per_second': 32.305, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 320, n_head = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON EMBEDDING PARAMETERS: 45838016, with commas 45,838,016\n",
      "NUMBER OF TOKENS: 77522944, with commas 77,522,944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37853' max='37853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37853/37853 2:03:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.327500</td>\n",
       "      <td>5.716834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.448100</td>\n",
       "      <td>5.326819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.160700</td>\n",
       "      <td>5.080652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.992200</td>\n",
       "      <td>4.923663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.814300</td>\n",
       "      <td>4.772987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.679600</td>\n",
       "      <td>4.605647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.544300</td>\n",
       "      <td>4.492287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.442400</td>\n",
       "      <td>4.409285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.360400</td>\n",
       "      <td>4.323043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.276600</td>\n",
       "      <td>4.250167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.202500</td>\n",
       "      <td>4.186943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.161100</td>\n",
       "      <td>4.127966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.112100</td>\n",
       "      <td>4.085073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.064800</td>\n",
       "      <td>4.033954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.011700</td>\n",
       "      <td>3.988789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.000500</td>\n",
       "      <td>3.959417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.963400</td>\n",
       "      <td>3.939453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.928900</td>\n",
       "      <td>3.900642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.891500</td>\n",
       "      <td>3.870284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.870300</td>\n",
       "      <td>3.853962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.834800</td>\n",
       "      <td>3.812873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.805300</td>\n",
       "      <td>3.805169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.797700</td>\n",
       "      <td>3.770089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.774600</td>\n",
       "      <td>3.750930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.749800</td>\n",
       "      <td>3.744701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.724700</td>\n",
       "      <td>3.722931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.727600</td>\n",
       "      <td>3.702272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>3.680955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.693600</td>\n",
       "      <td>3.672913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.657400</td>\n",
       "      <td>3.646818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.654100</td>\n",
       "      <td>3.638345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.633000</td>\n",
       "      <td>3.622716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.627000</td>\n",
       "      <td>3.609097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.613500</td>\n",
       "      <td>3.589399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>3.598600</td>\n",
       "      <td>3.585317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.604100</td>\n",
       "      <td>3.568221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>3.583200</td>\n",
       "      <td>3.557877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.556500</td>\n",
       "      <td>3.547138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>3.556200</td>\n",
       "      <td>3.534039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.541500</td>\n",
       "      <td>3.525890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>3.550500</td>\n",
       "      <td>3.511067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.517500</td>\n",
       "      <td>3.509012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>3.524200</td>\n",
       "      <td>3.496013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.516400</td>\n",
       "      <td>3.485514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>3.502400</td>\n",
       "      <td>3.470456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.467600</td>\n",
       "      <td>3.463616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.475800</td>\n",
       "      <td>3.452965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.469900</td>\n",
       "      <td>3.446196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>3.453600</td>\n",
       "      <td>3.436713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.466000</td>\n",
       "      <td>3.428903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>3.450600</td>\n",
       "      <td>3.421304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.439700</td>\n",
       "      <td>3.415229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>3.440200</td>\n",
       "      <td>3.412559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.426600</td>\n",
       "      <td>3.405193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>3.414200</td>\n",
       "      <td>3.397887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>3.412900</td>\n",
       "      <td>3.391703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>3.413900</td>\n",
       "      <td>3.387043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>3.386400</td>\n",
       "      <td>3.381184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>3.404300</td>\n",
       "      <td>3.375121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.388500</td>\n",
       "      <td>3.369981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>3.397700</td>\n",
       "      <td>3.366617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>3.392800</td>\n",
       "      <td>3.363693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>3.403300</td>\n",
       "      <td>3.359738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>3.386100</td>\n",
       "      <td>3.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>3.374200</td>\n",
       "      <td>3.352945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>3.370900</td>\n",
       "      <td>3.349807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>3.367100</td>\n",
       "      <td>3.348014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>3.356200</td>\n",
       "      <td>3.346146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>3.368000</td>\n",
       "      <td>3.344545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>3.358700</td>\n",
       "      <td>3.343566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>3.356800</td>\n",
       "      <td>3.342868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>3.357500</td>\n",
       "      <td>3.342073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>3.352400</td>\n",
       "      <td>3.341641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>3.363200</td>\n",
       "      <td>3.341480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>3.372000</td>\n",
       "      <td>3.341429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 21320987684634624\n",
      "Human Readable: 21,320,987,684,634,624\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.329268217086792, 'eval_runtime': 6.8597, 'eval_samples_per_second': 34.695, 'eval_steps_per_second': 17.348, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 448, n_head = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 22 layers\n",
      "NON EMBEDDING PARAMETERS: 69308416, with commas 69,308,416\n",
      "NUMBER OF TOKENS: 102674432, with commas 102,674,432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50134' max='50134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50134/50134 3:31:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.327900</td>\n",
       "      <td>5.709722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.474200</td>\n",
       "      <td>5.348254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.168500</td>\n",
       "      <td>5.094281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.998900</td>\n",
       "      <td>5.005149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.891400</td>\n",
       "      <td>4.878734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.770500</td>\n",
       "      <td>4.716152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.637200</td>\n",
       "      <td>4.609263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.519500</td>\n",
       "      <td>4.470326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.426500</td>\n",
       "      <td>4.394495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.345100</td>\n",
       "      <td>4.320373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.271700</td>\n",
       "      <td>4.238564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.193700</td>\n",
       "      <td>4.159550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.141500</td>\n",
       "      <td>4.104445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.073200</td>\n",
       "      <td>4.075042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.024800</td>\n",
       "      <td>4.019669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.012200</td>\n",
       "      <td>3.996829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.966200</td>\n",
       "      <td>3.946470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.917700</td>\n",
       "      <td>3.901366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.900100</td>\n",
       "      <td>3.886983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.900300</td>\n",
       "      <td>3.851015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.838700</td>\n",
       "      <td>3.836498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.830300</td>\n",
       "      <td>3.805321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.815700</td>\n",
       "      <td>3.785225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.775500</td>\n",
       "      <td>3.764884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.771400</td>\n",
       "      <td>3.746971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.743700</td>\n",
       "      <td>3.725244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.734100</td>\n",
       "      <td>3.710228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.692600</td>\n",
       "      <td>3.684728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>3.682437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.665000</td>\n",
       "      <td>3.660979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.645900</td>\n",
       "      <td>3.637091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.636200</td>\n",
       "      <td>3.626367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.619100</td>\n",
       "      <td>3.610645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.612000</td>\n",
       "      <td>3.602980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>3.632600</td>\n",
       "      <td>3.591956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.611700</td>\n",
       "      <td>3.574160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>3.593900</td>\n",
       "      <td>3.569230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.581800</td>\n",
       "      <td>3.559101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>3.561600</td>\n",
       "      <td>3.560237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.565600</td>\n",
       "      <td>3.538358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>3.555800</td>\n",
       "      <td>3.524550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.535000</td>\n",
       "      <td>3.511157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>3.538000</td>\n",
       "      <td>3.501019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.523200</td>\n",
       "      <td>3.488410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>3.496000</td>\n",
       "      <td>3.480106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.494300</td>\n",
       "      <td>3.468717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.468100</td>\n",
       "      <td>3.460431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.468900</td>\n",
       "      <td>3.451229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>3.477200</td>\n",
       "      <td>3.444416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.468000</td>\n",
       "      <td>3.434717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>3.437300</td>\n",
       "      <td>3.424021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.449600</td>\n",
       "      <td>3.414134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>3.428500</td>\n",
       "      <td>3.415330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.426700</td>\n",
       "      <td>3.400129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>3.417600</td>\n",
       "      <td>3.398633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>3.420200</td>\n",
       "      <td>3.393151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>3.416000</td>\n",
       "      <td>3.382264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>3.399900</td>\n",
       "      <td>3.374866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>3.376700</td>\n",
       "      <td>3.366565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.394500</td>\n",
       "      <td>3.361937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>3.364700</td>\n",
       "      <td>3.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>3.388500</td>\n",
       "      <td>3.347431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>3.372500</td>\n",
       "      <td>3.342456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>3.360900</td>\n",
       "      <td>3.335491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>3.352800</td>\n",
       "      <td>3.328044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>3.349700</td>\n",
       "      <td>3.326084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>3.346800</td>\n",
       "      <td>3.318103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>3.337900</td>\n",
       "      <td>3.309631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>3.336800</td>\n",
       "      <td>3.303457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>3.327200</td>\n",
       "      <td>3.296417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>3.324600</td>\n",
       "      <td>3.292793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>3.313800</td>\n",
       "      <td>3.288776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>3.309900</td>\n",
       "      <td>3.283687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>3.309500</td>\n",
       "      <td>3.281479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>3.308600</td>\n",
       "      <td>3.275953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>3.299100</td>\n",
       "      <td>3.273052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>3.300100</td>\n",
       "      <td>3.269046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>3.288000</td>\n",
       "      <td>3.263762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>3.301200</td>\n",
       "      <td>3.260211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>3.297300</td>\n",
       "      <td>3.259489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>3.270400</td>\n",
       "      <td>3.256735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>3.275300</td>\n",
       "      <td>3.252541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>3.288900</td>\n",
       "      <td>3.249302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>3.270500</td>\n",
       "      <td>3.247640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>3.287200</td>\n",
       "      <td>3.246154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>3.286500</td>\n",
       "      <td>3.243650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>3.269200</td>\n",
       "      <td>3.241821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>3.248800</td>\n",
       "      <td>3.239884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>3.271500</td>\n",
       "      <td>3.238567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>3.260100</td>\n",
       "      <td>3.237079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>3.265000</td>\n",
       "      <td>3.235532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>3.279200</td>\n",
       "      <td>3.235108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>3.252100</td>\n",
       "      <td>3.234111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>3.254300</td>\n",
       "      <td>3.233676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>3.262100</td>\n",
       "      <td>3.232989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>3.271100</td>\n",
       "      <td>3.232745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>3.266900</td>\n",
       "      <td>3.232452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>3.255200</td>\n",
       "      <td>3.232282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>3.247400</td>\n",
       "      <td>3.232229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>3.279900</td>\n",
       "      <td>3.232212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 42697213473718272\n",
      "Human Readable: 42,697,213,473,718,272\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2232205867767334, 'eval_runtime': 8.8866, 'eval_samples_per_second': 26.782, 'eval_steps_per_second': 13.391, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 512, n_head = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca540c53d32f>:58: RuntimeWarning: invalid value encountered in power\n",
      "  return (n_c / n)**a\n",
      "<ipython-input-5-ca540c53d32f>:58: RuntimeWarning: invalid value encountered in power\n",
      "  return (n_c / n)**a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 42932915937791.516 0.08903330047720337 2.585\n",
      "LEAP 28363515245975.594 0.09174780961091501 2.562\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABBf0lEQVR4nO3dd1xV5R/A8c/DBlFxK7hFURFEQFyAe5Q5G1aaWtnQnPWzYVlqw4blyJVlrsqynJl740pxK+XGBDcKioKs5/fHxSsq4FW53At836/XfcU95znnfO/x9uXwnOd8H6W1RgghRP5jY+kAhBBCmIckeCGEyKckwQshRD4lCV4IIfIpSfBCCJFPSYIXQoh8ys7SAWRUsmRJXblyZUuHIYQQecauXbsuaa1LZbbOqhJ85cqVCQ8Pt3QYQgiRZyilTmW1TrpohBAinzJbgldKeSml9mZ4XVVKDTbX8YQQQtzJbF00WuvDgB+AUsoWiAYWmut4Qggh7pRbffAtgeNa6yz7ioR4EMnJyURFRZGYmGjpUITIFU5OTpQvXx57e3uTt8mtBP8sMDeXjiUKgKioKAoXLkzlypVRSlk6HCHMSmtNTEwMUVFRVKlSxeTtzH6TVSnlAHQEfs9i/atKqXClVPjFixfNHY7IJxITEylRooQkd1EgKKUoUaLEA//FmhujaB4Ddmutz2e2Ums9TWsdqLUOLFUq06Gcpkm68fDbijxJkrsoSB7m+54bCf45zN09czIMxvvCgT9A6tuLXHL+/Hmef/55qlatSkBAAI0aNWLhQsM4gg0bNlC0aFHq1atHrVq1GDlyJCtXrsTPzw8/Pz9cXV3x8vLCz8+Pnj17snr1agICAvDx8SEgIIB169ZZ+NPdKTIykjp16uTKsZo1a3bf52FMaWMuu3btwsfHB09PTwYOHEhWc2qMHj0aT09PvLy8WLlypXH53Llz8fHxwdfXl3bt2nHp0iUATp06RcuWLfH19aVZs2ZERUU9erBaa7O9ABcgBihqSvuAgAD9UM5HaP1dM60/KqL1L89qHRf9cPsReUZERIRFj5+WlqYbNmyop0yZYlwWGRmpJ0yYoLXWev369bp9+/Zaa63j4+O1p6enDg8PN7Zt2rSp3rlzp/H97t27dXS04Xt74MAB7e7unhsfwyTJycn65MmT2tvbO1eOd/e5edg25lK/fn29detWnZaWptu1a6eXLVt2T5tDhw5pX19fnZiYqE+cOKGrVq2qU1JSdHJysi5VqpS+ePGi1lrroUOH6o8++khrrfVTTz2lZ86cqbXWeu3atbpHjx737Dez7z0QrrPIqWa9gtda39Bal9Bax5nzOJSuBX3WQJtP4fh6mNQA9v5i1kOKgm3dunU4ODjw+uuvG5dVqlSJAQMG3NO2UKFCBAQEcPz48Sz3V69ePdzd3QHw9vYmMTGRmzdv3tOucuXKvPPOOwQFBREUFMSxY8eAO6/+WrZsyX///UdqaipVq1ZFa01sbCw2NjZs2rQJgJCQEI4dO8b169d56aWXqF+/PvXq1WPx4sUAzJw5k6effpoOHTrQpk2bO2KIjIwkJCQEf39//P392bp1KwD9+vVjyZIlAHTp0oWXXnoJgOnTp/PBBx/c81n69u1LYGAg3t7efPTRR5meF1dXV9566y38/f1p2bIlGe/T/f777wQFBVGjRg3CwsKyjS2nnD17lqtXr9KoUSOUUvTs2ZNFixbd027x4sU8++yzODo6UqVKFTw9PdmxY4cx8V6/fh2tNVevXjX+u0dERNCyZUsAmjdvbvy3eBRWVargkdjYQuP+UPNxWDIQbsZbOiKRi7p9t+2eZU/4luOFRpVJSEql94wd96x/KqA8TwdW4PL1JPr+tOuOdb+91ijb4x06dAh/f3+TYouJiWH79u0MHz7cpPbz58+nXr16ODo6Zrq+SJEi7Nixg9mzZzN48GCWLl1K//796dmzJ7169eLHH39k4MCBLFq0iBo1ahAREcHJkycJCAggLCyMBg0aEBUVhaenJ8OGDaNFixb8+OOPxMbGEhQURKtWrQDYtm0b+/fvp3jx4kRGRhqPX7p0aVavXo2TkxNHjx7lueeeIzw8nNDQUMLCwujYsSPR0dGcPXsWgM2bN/Pss8/e8zk+/fRTihcvTmpqKi1btmT//v34+vre0eb69ev4+/vz9ddfM2rUKEaOHMnEiRMBSElJYceOHSxbtoyRI0eyZs2aLGO7W0hICNeuXbtn+ZgxY4yfPzPR0dGUL1/e+L58+fJER0dn2q5hw4b3tGvUqBFTpkzBx8eHQoUKUb16dSZNmgRA3bp1mT9/PoMGDWLhwoVcu3aNmJgYSpQokWU895MvEnxSShpr/jnPY3XKoopXhV5/3u6LP/AHXDsHDfsafgkIYQZvvPEGmzdvxsHBgZ07dwIQFhZGvXr1sLGx4d1338Xb2/u++zl06BDvvPMOq1atyrLNc889Z/zvkCFDAEMyXrBgAQAvvPACb7/9NmBIZJs2beLkyZO89957fP/99zRt2pT69esDsGrVKpYsWcKYMWMAw+ik//77D4DWrVtTvHjxe46fnJxM//792bt3L7a2thw5csR4rHHjxhEREUHt2rW5cuUKZ8+eZdu2bUyYMOGe/cybN49p06aRkpLC2bNniYiIuCfB29jY0K1bNwB69OhB165djetu/RwQEGD8BZRVbHe7dcX/oHQm/e2Z3fzMql1ycjJTpkxhz549VK1alQEDBjB69Gg++OADxowZQ//+/Zk5cyahoaF4eHhgZ/doKTpfJPhFe6J5e/5+mniW4NPOPlQuWQhunfRja2HfL3BoAXScCGVqWzZYYRbZXXE7O9hmu754IYf7XrHfzdvbm/nz5xvfT5o0iUuXLhEYGGhcFhISwtKlS03eZ1RUFF26dGH27NlUq1Yty3YZE0pWIytuLQ8JCWHq1KmcOXOGUaNG8dVXX7FhwwZCQ0MBQyKaP38+Xl5ed2z/999/U6hQoUz3PXbsWMqUKcO+fftIS0vDyckJAA8PD65cucKKFSsIDQ3l8uXLzJs3D1dXVwoXLnzHPk6ePMmYMWPYuXMnxYoVo3fv3iYNAcz4eW/9hWNra0tKSkq2sd3N1Cv41NRUAgICAOjYsSN9+/a94+ZnVFSUsYslo/Lly3P69Ol72u3duxfA+O/7zDPP8PnnnwPg7u5u/CUdHx/P/PnzKVq06H3OSPbyRbGxpwLK80nnOuw/HUfbcZuYtP4YyalphpWdJ8OT0+FKJHwXChs+h5Qki8Yr8r4WLVqQmJjIlClTjMtu3Hj4obqxsbG0b9+e0aNH06RJk2zb/vbbb8b/Nmpk+MXUuHFjfv31VwB+/vlngoODAWjQoAFbt27FxsYGJycn/Pz8+O677wgJCQGgbdu2fPvtt8Yrzj179tw31ri4OMqVK4eNjQ1z5swhNTXVuK5Ro0aMGzeO0NBQQkJCGDNmjPFYGV29epVChQpRtGhRzp8/z/LlyzM9VlpaGn/88QcAv/zyi/FzPUxsGYWFhbF37957Xnd3z9ja2hrXjRo1inLlylG4cGG2b9+O1prZs2fTqVOne/bfsWNHfv31V27evMnJkyc5evQoQUFBeHh4EBERYbyXsHr1amrVqgXApUuXSEsz5K3Ro0cb72E8inyR4G1sFD0aVmLNW01pWas0X608zFvz9hlWKgU+T8EbO8G7C2wYDZGbLBuwyPOUUixatIiNGzdSpUoVgoKC6NWrF1988cVD7W/ixIkcO3aMjz/+2DiU8sKFC5m2vXnzJg0aNGD8+PGMHTsWgAkTJjBjxgx8fX2ZM2cO48ePBwxXuRUqVDD2B9+6cvXx8QFg+PDhJCcn4+vrS506dUy6T9CvXz9mzZpFw4YNOXLkyB1X+iEhIaSkpODp6Ym/vz+XL1/ONMHXrVuXevXq4e3tzUsvvZTlL7VChQpx6NAh49DRDz/88KFjyylTpkyhT58+eHp6Uq1aNR577DEAlixZYozP29ubZ555htq1a9OuXTsmTZqEra0t7u7ufPTRR4SGhuLr68vevXsZNmwYYBha6+XlRY0aNTh//jzvv//+I8eqMusrspTAwECdE2Nb10Scp0wRJ3zKF+VqYjIARZzS6zec2QPu9Qw/H18PFRqAg8sjH1Pkrn/++cd45VOQ3JozoWTJkpYOJVe4uroSHy8DJm7J7HuvlNqltQ7MrH2+uIK/W6vaZfApb+i7Gr3sX1p9vZHlB84a/gy9ldzjL8Av3WBKIzix0YLRCiGEeeTLBJ/Rc0EVKOnqSN+fd/PK7HDOxCYYVriWhh7zAQWzOxqGVibEWjJUIe4rMjKywFy9A3L1/ojyfYL3Le/Gkv5NeP/xWmw5FkPrbzayJiK9LE6VEOi7FRoPhD1zYEoTSLpu2YCFECKH5IthkvdjZ2vDK6FVaVenLJ/+9Q+13IsAkJamsXFwgTYfG27ARoWDQ/pNmaTrt38WQog8KN9fwWdUobgLU18IwMPNGa01L83ayWfL/uFGUgp4+EODVw0NT2yEcT6w/3cpXiaEyLMKVILPKCk1jXJFnZi26QRtxm5iw+EMQ9IKl4XiVWFBH8ON2LgcqOomhBC5rMAmeEc7W0Z39eW3VxviaGdD7xk7GTB3D1euJ0EpL3hpJbQdDZFhMKkh7PnJ0iELK+Pq6nrPshEjRuDh4WEcy+7n50dsbKxx/aBBg/Dw8DA+0AKGwl6lSpXCz8+P2rVr8/333+dG+Cbr3bu38WEjc9qwYQNPPPHEI7cxF601AwcOxNPTE19fX3bv3p1pu5MnT9KgQQOqV69Ot27dSEoyPFh55coVunTpgq+vL0FBQRw8eBCA06dP07x5c2rVqoW3t7fxGYacUGAT/C0NqpZg2aAQBreqzr7TsdjZpj8KbWMLjfoZbsJ6+MuEIsJkQ4YMuePpSDc3N8DwVObChQupUKGCsarjLd26dWPv3r1s2LCBYcOGcf58pvPj5LqsngQtiJYvX87Ro0c5evQo06ZNo2/fvpm2e+eddxgyZAhHjx6lWLFiTJ8+HYDPPvsMPz8/9u/fz+zZsxk0aBAAdnZ2fP311/zzzz9s376dSZMmERERkSMxF/gED4ar+cGtarD6zVAKO9mTlJLGO3/s59iFeCheBXouhvp9DI33/w5bxkNqimWDFnnO+vXrqVOnDn379mXu3MznwCldujTVqlXj1Kk756efOXMmnTp1ol27dnh5eTFy5Ejjum+++YY6depQp04dxo0bB8CXX35pLPA1ZMgQWrRoAcDatWvp0aMHYCg01qhRI/z9/Xn66aeNQxIrV67MqFGjCA4O5vff75xpc9SoUdSvX586derw6quvorXmwoULxnot+/btQyllLFhWrVq1e0o47Nixg8aNG1OvXj0aN27M4cOH7zkPI0aM4IUXXqBFixZUr179jr9q4uPjeeqpp6hZsybdu3c3llnILLactHjxYnr27IlSioYNGxIbG2usmHmL1pp169bx1FNPAdCrVy9jOeGM5YBr1qxJZGQk58+fp1y5csbKpIULF6ZWrVqZVqh8GJLgM3C0M1SbPHrhGisOnePx8WGMXX2Em6lpYJN+qk5sgNUfwvRWcO6g5YIVd5rR/t7XjvSkkHQj8/V7fjasvx5z77pHMHbsWGP3TPPmzY3L586dy3PPPUeXLl1YunQpycnJ92x74sQJTpw4gaen5z3rduzYwc8//8zevXv5/fffCQ8PZ9euXcyYMYO///6b7du38/3337Nnzx5j6V6A8PBw4uPjSU5OZvPmzYSEhHDp0iU++eQT1qxZw+7duwkMDOSbb74xHsvJySnTMr/9+/dn586dHDx4kISEBJYuXUrp0qVJTEzk6tWrhIWFERgYSFhYGKdOnaJ06dK4uNz5pHjNmjXZtGkTe/bsYdSoUcZH9e+2f/9+/vrrL7Zt28aoUaM4c+YMYKiXc6tq5YkTJ9iyZUuWsd3t559/vqP77NbrVkLOTnR0NBUqVDC+z6xUcExMDG5ubsYqkBnb1K1b11hMbMeOHZw6deqeWZsiIyPZs2cPDRo0uG88pigQwyQflLd7Uda+1ZSPl0Ywfu1R/tx/hs+6+NCwagnoNBGqt4JlQ2FaUwh+E0L/B3aZ1+4WBc+QIUP43//+d8eypKQkli1bxtixYylcuDANGjRg1apVtG9v+GXy22+/sXnzZhwdHfnuu+8yLdPbunVrY23wrl27snnzZpRSdOnSxVhzpWvXroSFhdG3b1927drFtWvXcHR0xN/fn/DwcMLCwpgwYQLbt28nIiLCWAMmKSnJWLgMMJbovdv69ev58ssvuXHjBpcvX8bb25sOHTrQuHFjtmzZwqZNmxg2bBgrVqxAa51pHZq4uDh69erF0aNHjSV0M9OpUyecnZ1xdnamefPm7NixAzc3N4KCgow12f38/IiMjCQ4ODjL2DLq3r073bt3z/R492NKqeDs2rz77rsMGjQIPz8/fHx8qFev3h3lgOPj43nyyScZN24cRYoUeagY7yYJPgslXR0Z/2w9uvqX54NFB/h4aQR/9g/GxkYZxsxXaQor3oVNX0LFBuCZ9SQBIhe8+FfW6xxcsl9fqET263PAihUriIuLMxb5unHjBi4uLsYE361bN+NEFlm5O5kopbLshrC3t6dy5crMmDGDxo0b4+vry/r16zl+/Di1atXi+PHjtG7dOsuuosyKdCUmJtKvXz/Cw8OpUKECI0aMMJb4DQkJMV61d+rUiS+++AKlVKY3RIcPH07z5s1ZuHAhkZGRNGvWzOTPC9wxEcqtUsHZxZbRzz//zFdffXXPck9Pz3tuJE+aNMnYNbRs2bIsSwBnVLJkSWJjY0lJScHOzu6ONkWKFGHGjBmA4RdBlSpVqFKlCmCoY//kk0/SvXv3O2rePyrpormPpjVKsWpwU6b2CMDGRhF3I5k/951BOxeDrtPgtU23k/uxtfIkrMjU3Llz+eGHH4iMjCQyMpKTJ0+yatWqByoxvHr1ai5fvkxCQgKLFi2iSZMmhIaGsmjRIm7cuMH169dZuHCh8ao5NDSUMWPGGEv3Tp06FT8/P2Mf8pYtW4xT/t24cSPLyTFuuZUwS5YsSXx8/B0JMTQ0lJ9++onq1atjY2ND8eLFWbZsWaZVIuPi4vDw8AAM9xaysnjxYhITE4mJiWHDhg3GSUoeNLaMunfvnmmZ4Mzav/HGG8b17u7udOzYkdmzZ6O1Zvv27RQtWpRy5crdsY1SiubNmxv3N2vWLGM54djYWOOImh9++IHQ0FCKFCmC1pqXX36ZWrVq8eabb2b5GR+GJHgTODvYUqG4oR9xzvZIBszdQ68ZOzl9+QaUq2toFH8Rfn0eJjc0VKkU+d6NGzcoX7688XWrDztjH7yfnx8RERGsXLnSeLUOhivk4OBg/vzzT5OPFxwczAsvvICfnx9PPvkkgYGB+Pv707t3b4KCgmjQoAF9+vShXj1DQb2QkBDOnj1Lo0aNKFOmDE5OTsbkX6pUKWbOnMlzzz2Hr68vDRs25N9//832+G5ubrzyyiv4+PjQuXPnOxJu5cqVAYwTiQQHB+Pm5kaxYsXu2c/bb7/Ne++9R5MmTbIdpRMUFET79u1p2LAhw4cPz3RiDVNiyymPP/44VatWxdPTk1deeYXJkyffse7WPYIvvviCb775Bk9PT2JiYnj55ZcBQyVIb29vatasyfLly43DIbds2cKcOXNYt26d8TuzbNmyHIk5X5YLNqfUNM2cbZF8tfIwqVozuFUNXg6ugr2tDZzaCksGQMwxqNcD2nwCzvd+wcWjK2jlgmfOnEl4ePh9u3HyixEjRuDq6nrPvYyCTsoFm5mtjaJ3kyqseaspIdVL8fnyf/ls2T+GlZUaw+tbIHgI7J0LU4Kly0YIYTFyBf8w9s+DtaMgLooVjm3xafYUHo2e5sLVRFwc7XB1tIMzeyFqJwS9YtjmZjw43vvko3g4Be0KXgh48Ct4GUXzoPbPgz8HQrKhrny7mytg3UYopBkaXpkj568xsqM3bbz9wN3PsM2JjfB7b2j7GdR99vaE4EIIYUbSRfOg1o4yJnej5ARYO4pBrapT1NmeV+fs4rU54ZyLSx+mVbgclPCERa/Dz09B7Ol79ysemDX99SmEuT3M910S/IPKqrJkXBT+FYvx54Bg3m7nxYbDF2n1zUb+PhEDpWrASyvgsS/h1DbDSJvds3M37nzGycmJmJgYSfKiQNBaExMTg5OT0wNtZ9YuGqWUG/ADUAfQwEta623mPKa53XAui0vC2cyXA/a2NvRr5kl7n3KMW3OU2umTiyRrhX2D16BGO1g6GFJu5m7g+Uz58uWJiori4sWLlg5FiFzh5ORkfILXVObugx8PrNBaP6WUcgBc7reBtfsyuRtv68m4qCTjshvagS+TuzEiQ7tKJQoxtpsfAEkpaXSetIVmXqUY2LI6Tj0W3J5IZN9vcDXaMG2grdwSMZW9vb3xKUAhRObM1kWjlCoChALTAbTWSVrrWHMdL7fMig/i3eQ+RKWVJE0rotJK8m5yH2bFB2W5TVJqGrXdizB5w3HajtvE5mMxt4uXndoMa0fCDy3g7P5c+hRCiILAbMMklVJ+wDQgAqgL7AIGaa2zHBieF4ZJNvl8HdGxCfcs93BzZsu7LbLdduvxS7y/8CAnL12nSz0PPu5cxzCkMmIx/PU/uBEDwYMh9G2wf7C+NiFEwWSpB53sAH9gita6HnAdeDeT4F5VSoUrpcLzQn/q0LZeONvb3rHM2d6WoW297rtt42olWT4ohIEtPDl56TpOdumnv3YneONvwxDKsK8NV/VCCPGIzHkFXxbYrrWunP4+BHhXa51lse28cAUPsGhPNF+tPMyZ2ATc3ZwZ2taLzvU8HmgfqWka2/TiZcMWHuCtNjWoWsoVzh2AsoaKgxxdAxUbygNSQogsWeRBJ631OaXUaaWUl9b6MNASQ3dNnte5nscDJ/S72doYHnb659xVNh29yOp/zjOguSevNfXGAW4XL3MtAx3GgWfLR45bCFGwmHsc/ADgZ6XUfsAP+MzMx8tzGlYtwdo3m9K6dhm+Xn2E9hPCCI+8DK6loNcSw0QiP3WFRf3gxmVLhyuEyEOkFo0VWffveYYvOkStcoX5oVd6udPkRMOkIpvHGa7mB4SDw72TMQghCiapRZNHtKhZhgZDSpCQbKiRfSrmOgei42jfYjiqdmeI2nE7ud+8Bo6FLResEMLqSakCK1PI0Y6SroYpyWZsiaT/L3t4eVY4UU6eUL+PodGJDTC2jmHSaCv6C0wIYV0kwVuxD9rX4oP2tdh2PIbW32zih7ATpKSmQZHyULoWLO4Hc7rAlVOWDlUIYYUkwVsxO1sb+oRUZfWboTSqVoJP/vqHaWEnoKQn9F4Gj48x1Jyf3AjCZ2S/s/3zDFf9I9wM/90/L1c+gxDCcqQPPg8oX8yF6b0CWXHwHMHVSwJw8nICpeu+SKEabWHpEEhLyXoHd9WwJ+604T2A7zNmjl4IYSmS4PMIpRSP+RhmcE9L07w+ZxfxN1P4uLM3LbpnmBF+32+GBN5kENjaG5ZlU8NeErwQ+Zd00eRBNjaKT7vUwcXBlpdmhvPG3D1ciE8vP/zfVlj3MXzf3DBtIGRbw14IkX9Jgs+jAisX56+BIfyvTQ1WR5yn5dcb+efsVegwHrr9BPEX4PsWsGYEFHHPfCdFH6y2tBAib5EEn4c52NnQv0V1VgwKoZOfO9VLG2rWJHo+bihe5vccbB4LPk+DvfOdG9s7Q8sP738QuTkrRJ4lffD5QNVSrnzS2VCgLPZGEo+ND+PpgPL0e3wCTg37QRlvdia4U233J7jpq1xQpTjtM5T69+t/l5uzQuRpcgWfDzWqWoIJ647x+PgwtsaXYdGeaAbvdKOQTuAsJXg36UV67qzEoj3R2e8ou5uzQgirJwk+n3FzceCbbn7MeTmIlDTN89//zbCFB4hOduXZpA+4rp2Y6fAln/At363Ymf3O5OasEHmaJPh8KqR6KVYODqVvs2rcSDLUttmjq/NE0meMT+lCR5ttzEgcDElZTrCV9U1YuTkrRJ4gCT4fc3aw5Z12NXEvenv6vyTsGZvyNB2SPmW2fbfbxcsSr967g5YfkmJ759SBKbZOpt2cFUJYnCT4AuDtdjXvmWbwmKpEtccGGN4cXwfj6sDu2XcUL1uU2iTTCcYXpTbJzfCFEA9JRtEUALdmn/pq5WGiYxNwsrchMTmN78NOUKVUIfzdKkEZH1gyAA78YRhLX7yKoX1SY/6g8R3727by8CPPaCWEML/7JnilVCEgQWudppSqAdQElmutk80encgxd08zuOrQOT5cfIgle8/g39Ebev0Ju2fCqg9hSmNo+ylnYstkuq8zsQmZLhdCWBdTruA3ASFKqWLAWiAc6AZ0N2dgwrzaeJelsWdJVPr73VFxXHB6nHZvtDEUL9MadzdnojNJ5u5uzvcsE0JYH1MSvNJa31BKvQx8q7X+Uim1x9yBCfNzdbz9z//j5pMs3X+W1rXLMKrjLMoVdWao3Rm2L5xI6dQLTEntSDJ2ONvbMrStlwWjFkKYyqQEr5RqhOGK/eUH2E7kIWO7+VHHoyjj1hyh1Teb+F9bL3o2qkzdfTFUifyDx23/5iungXR4rL30vwuRR5gyimYw8B6wUGt9SClVFVhv1qhErrO3teH1ptVYPaQpAZWLM/LPCBbuiaZK72nw7FxqFk1hevI7dL44BZJuWDpcIYQJlH6AOT2VUjaAq9Y6k0HTjy4wMFCHh4ebY9fiAWitWfPPBZp7lcLO1oaD0XFUK5yK84YRsHsW9FgAni0tHaYQAlBK7dJaB2a27r5X8EqpX5RSRdJH00QAh5VSQ3M6SGE9lFK0rl0GO1sbEpNT6T1jJ22m7mVTzeHQ7+/byf3IyswfkBJCWAVTumhqp1+xdwaWARWBF8wZlLAeTva2THy+Hva2NvT8cQeD1yVwKf4mxF+EeT1hckNDohdCWB1TEry9UsoeQ4JfnD7+3fR+HZHnNaxaguWDQhjUsjrLDpyj1TcbOZPiapj426ko/PIMzO8D1y9ZOlQhRAamJPjvgEigELBJKVUJkL/LCxhHO1uGtK7BskEh9GxYiXJFnaB8ANd6rYGm78KhRTClCdyMt3SoQoh0D3ST1biRUnZa65ScDkZusuYtp2Ku88S3m+kTXJW+tRNxOLsLAnobVibEgrObBaMTomB41JusRZVS3yilwtNfX2O4mhcFnIuDHc28SjN2zREe//UyO4p3NKw4thbG+UD4DEhLs2yQQhRgpnTR/AhcA55Jf10FZpgzKJE3lCrsyLfP1WPGi/VJSErlme+28f7CA+jiVcHdD5YOhtkd4fIJS4cqRIFkSoKvprX+SGt9Iv01Eqhq7sBE3tHcqzSr3wzl1dCqONrZoopXgZ5LoMMEOLsPJjeGnT9YOkwhChxTEnyCUir41hulVBNAygmKO7g42DHs8VoMf6IWADtPXeHF/bU4030DVG0Gyjbb7YUQOc+UmjKvA7OVUkXT318BepkvJJGXKWWoT3kmNoG/T16m5feXGdLqE17yq2L4su39Ba6cgpC3wM7BorEKkd/d9wpea71Pa10X8AV8tdb1gBZmj0zkaZ38PFjzZlOaeJbks+WH6TR5K/ujYiF6N2z8HL4Lhahdlg5TiHzN5Cn7tNZXM9SgedOUbZRSkUqpA0qpvUopGf9YwLi7OfN9zwCmdPfn4rWb/H3iMrQfA8/Pg5tXYXorWPm+FC8Twkwetuyvun8To+Zaa3nEsYBSSvGYTzmaVC+JS/q8sKuS62Lf8k+an54I2yYaattUkz8KhchpDzvptpQqEA+kiJM9draGr9usbZG8OPdf+sb24FKvsNvJ/d9lhgekhBA5IssEr5S6ppS6msnrGuBu4v41sEoptUsp9WoWx3n11kNUFy9efIiPIPKaGb2DGNrWi7X/XqD5zLPM2X6KtGsX4Y8XYVID+PcvS4coRL7wUKUKTN65Uu5a6zNKqdLAamCA1npTVu2lVEHBEnnpOu8vOsCWYzHMeTmIEJfTsLg/XDgE3l3hsS/BtZSlwxTCqmVXqsCsCf6uIEYA8VrrMVm1kQRf8Git2XIshiaeJVBK8ffRs/hHzcZ+8xhwcoOBe8DR1dJhCmG1skvwZptbNX2CEBut9bX0n9sAo8x1PJE3KaUIrl4SgJj4m/SavZeyRYIY+9gS6tkcvZ3cE66AczELRipE3vOwN1lNUQbYrJTaB+wA/tJarzDj8UQeV8LVkem96gPQ5Y/LvHWsLpevJ8GxNTDWB3ZOl+JlQjyA+3bRKKX6Az9rra+YOxjpohEAicmpTFx3jKkbj+PmYs/6PlUovOotOLEBKgVDxwlQopqlwxTCKjxSuWCgLLBTKTVPKdVO3XoWXQgzcbK35X9tvfhrYAgDWlSncFlPeGER19uNg3MHYEpj2PG9pcMUwuqZUqrgA6A6MB3oDRxVSn2mlJJLKGFWXmUL06txZcBQvCzgr7LMqPcbadVago3Zbh8JkW+Y1AevDf0459JfKUAx4A+l1JdmjE0Io4rFXWhRszQjN1zmsbOvsatkJ8OKPT/Buk8g5aZlAxTCCpkyo9NApdQu4EtgC+Cjte4LBABPmjk+IQAoU8SJyd0D+KFnINdupvDUd9v4bNk/cHY/bPoKpobA6R2WDlMIq2LK37klga5a61MZF2qt05RST5gnLCEy16p2GRpVK8HXq45QtogTBH+Jrt4alg5GTW8DDV6HFh880Nj5RXui+WrlYc7EJuDu5szQtl50rudhxk8hRO4w6UEnpZQ/EIyh9MAWrfVucwQjo2jEw1i8N5pVe47xhdsiXPfNgB7zDQXMTLBoTzTvLThAQnKqcZmzvS2ju/pIkhd5wqNOuj0cmAWUwHA1P0Mp9UHOhijEw7t+M5V1JxII2tOWPxotIrXqreJlf923eNlXKw/fkdwBEpJT+WrlYTNFK0TuMeUm6/NA/fR5WT8CGgLdzRuWEKZ7vkFFVg0JJahKcf63/jpdJm/h3+Mn4I+XDMXL/lma5bZnYjOffTKr5ULkJaYk+EjAKcN7R+C4WaIR4iFVKO7CjN71+fa5epyJTSAywRleWmkoVvZbd5jXC+Iv3LOdu5szHW02s9lhICccn2ezw0A62mzG3c3ZAp9CiJxlyk3Wm8AhpdRqDH3wrTGUIJgAoLUeaMb4hDCZUooOdd1pXrM0hRxsQZVjbt1ZNCj9E1UPTYRTW+8pXjau9lHq7PoBZ5UEQHl1iS/sf+Bg7crIzJQirzMlwS9Mf92ywTyhCJEzXB0NX+vUNM1PO8/w3plA+tT8noFesRS5ldxvXAaX4tQ//i2kJ/dbnFWSYTmv5XLkQuSs+yZ4rfUspZQDUCN90WGtdbJ5wxLi0dnaKBb0a8zUDSeYtP4Y8yLLMcz2P55xO4zNH72h5UcQdzrzjeOicjVWIczBlFE0zYCjwCRgMnBEKRVq3rCEyBmOdrYMalWd5YNDqFWuCO8tPMAJ5QEVgmD5ULB1yHzDouVzN1AhzMCULpqvgTZa68MASqkawFwMT7IKkSdUK+XKr682ZM/pWDwrFgPPBRxaPpXae0ahUu/sosHeGVp+aJlAhchBpoyisb+V3AG01kcAe/OFJIR5KKXwr2iYNOT4peu031SRpxwmE1MiIH0yEQVFK0CHCeD7jGWDFSIHmJLgdymlpiulmqW/vgd2mTswIcypWilXZr0UxAVdlIDot3i76iJi374ATd+BC/9AcqKlQxTikZky4Ycj8AaGUgUK2ARM1lrnePk+KVUgcltCUirj1h7hh7CTuLs5saHOSmx3TIUS1aHTRKjY0NIhCpGth550WyllA+zXWtcxV3AZSYIXlnLoTBzHL16nY1139LG1pC0ZhO3VKAh61dAfLxN/Cyv10LVotNZpwD6lVEWzRCaElfB2L0rHuu4ALImvSf0rH3Og/LPoHdMgSsoQi7zJlFE05TA8yboDuH5roda6o9miEsKCgqoUJ6B6BTpEdKBl6WYMdPCnLkDEEqgcDC7FLR2iECYxpQ++aWbLtdYbczoY6aIR1mTFwXN8tOQgF67dZFhoKV7Z1REcC0P7MVC7k6XDEwJ49Em3H9dab8z4Ah7P2RCFsD7t6pRl9ZtNeaFhJSpUqAAvr0IXKQfzesJvPeDaOUuHKES2TEnwrTNZ9lhOByKENSriZM+oTnVoV6cclPNlSvVpLCj+CvrIKpgaDDfjLR2iEFnKsg9eKdUX6AdUVUrtz7CqMLDV3IEJYY0c7B1470JLptt6816VazSyL4QtwPUYKFTC0uEJcYcs++CVUkWBYsBo4N0Mq65prS+bIxjpgxd5wamY63yw6CBhRy/hV8GNSfUv4bG6r2E4ZdArYGNr6RBFAfJQffBa6zitdaTW+jkgCkjGUA/eVYZNioKsUolCzH4piLHd6hJ1JYG4wp5QqTGseAd+bAcXs5/ub9GeaJp8vo4q7/5Fk8/XsWhPdC5FLgoaU0bR9AdGAOeBtPTFWmvtm9PByBW8yGsSk1NxsrcFrVkxdwItI7/BPvUGtBoJjfrd014m+RY57VFH0QwGvLTW3lprn/RXjid3IfIiJ3tDd8yN5FS+PFuXhldHs8elCde0Y6btZZJvkZtMedDpNBBn7kCEyMtcHOxYNjCEyeuP8cxGNwqttmWYw2meVutQl49Ds/fA3pnAq6v5zWEe7uoSZ3RJvkx5hiVpwTLJtzALUxL8CWCDUuovDPOzAqC1/sZsUQmRBznZ2/JmGy861HXnvQUHGLHkEO0DD1Fo93fwz1Ko05XPHabjnP6/UXl1ic/tf4Bk2FUks9HIQjwaUxL8f+kvh/SXECIb1csUZt5rjThy4RqFyrZDez/OjflvUGjTVzjf1dZFJfGO/Tx2tu1vkVhF/mbKnKwj716mlDLlF4MQBZaNjaJm2SIA7FA+9L48io/tZvCkbRhK3dnWXcXIDVZhFlneZFVKbc7w85y7Vkt5PSFM1KBqCSb1DmZs2rOEJo3lveSXidMuxvVK5n8VZpLdKJpCGX6+ux78XdcgQojstKhZhlVPOtDGbh+/pTanX9IgjCOUvR6D+wxXFuJhZNfVorP4ObP3Qoj7KBTwDMPtofOKiVy9Fo8qXIY0OydsdkyDq2fg8TFQpJylwxT5SHYJ3k0p1QXDVb6bUqpr+nIFFDV7ZELkR77P4JNhQu/v1v3LtQ3f8uaR37H9Lxg1aJ/MHiVyTHYJfiPQMcPPHTKs22S2iIQoQDrUq8iH//Wm5WF/OrpE0fZSKnU8gOuXoFBJS4cn8rj7lirITVKqQBREWmv+OnCWkX9GEBN/k+8axND60DvQ4gNo8LoULxPZetRSBUIIM1JK8YSvO2vebMpzQRXxqFkfqoTCymEwvQ1c+MfSIYo8ShK8EFaiqLM9n3bxoXbNWvDcr/xa4SOunTuKnhoCWydaOjyRB0mCF8IKaSCmakda3fyK5WlBbDuTQlqa9XSnirzhvk+kKqWeBlZora8ppT4A/IFPtNa7zR6dEAWUUoo3mnvyWJ2yvL+wEtvCLxF4cRtTax+kZOIpaP4+OLjcf0eiQDPlCn54enIPBtoCs4Apph5AKWWrlNqjlFr6sEEKUVBVLeXKL6804Kun6nI2LhHHuOOwbSJ8XgFGFIWxdWD/PEuHKayUKQn+VvHq9sAUrfViHqzo2CBA7hIJ8ZCUUjwdWIGNQ5tRuHIAKcqemNT0smVxp0lZ1F+SvMiUKQk+Win1HfAMsEwp5WjidiilymP4xfDDw4cohACws7XhxvIPuZzmwrNJHzAtpT2pWpGQqrix/ENLhyeskCmJ+hlgJdBOax0LFAeGmrj/ccDb3J7q7x5KqVeVUuFKqfCLFy+auFshCianhHOUVnEscRjOFe1Ky6QxNL05jhXx1dAHFxgekBIinSkJvhzwl9b6qFKqGfA0JlSTVEo9AVzQWu/Krp3WeprWOlBrHViqVCkTwhGi4DqTVgIAZ5XEO/a/MdV+HJXUeSYld4RF/WBSEBz4Q4qXCcC0BD8fSFVKeQLTgSrALyZs1wToqJSKBH4FWiilfnrYQIUQ8INDD27o27fAatqcZrb9Z/i5xKBeWUeaW2WY/zJpv3SDuGjLBSqsgikJPk1rnQJ0BcZprYdguKrPltb6Pa11ea11ZeBZYJ3WuscjRStEAefX/lU+1K8SlVaSNK2ISivJSF4hpEMvKFOb5Q1m83FyD5KOrid5SjDcjLd0yMKCTJmZKVkp9RzQk9sFx+zNF5IQIiuGmZ/60W1lS87EJuDu5szQtl7GGaHa1y2Pvd1wnl/UmIrXDlJkRSRD23pROOUKuJa2bPAi19232JhSqjbwOrBNaz1XKVUF6Ka1/jyng5FiY0LkjPibKYxZeZhZ2yIZWP4EQ658Cs2HQcN+YCszbuYn2RUbM6mapFLKAaiR/vaw1jo5B+MzkgQvRM7aezoW58TzeIWPgMPLSCrjh0PXyVDG29KhiRzySNUk00fOHAUmAZOBI0qp0JwMUAhhHn4V3PCq7gXP/sKvlUZy7dwJ0qaGkrZ5vKVDE7nAlJusXwNttNZNtdahGMoVjDVvWEKIHKUUTTq9yvDyP7IopSETt8cQceaqpaMSZmZKgrfXWh++9UZrfQS5ySpEnlOhuAuT+rTC9slpzEoIocPEzexe8A2sGAZJ1y0dnjADUxL8LqXUdKVUs/TX90C2Dy8JIayTUopOfh6sfaspz9avQHX7i7B9EnpyYzix0dLhiRxmyigaR+ANIBjDhNubgMla65s5HYzcZBUi9+mTYZz/+VXKppwh0acHTo9/Cs5ulg5LmOihb7IqpWyAXVrrb7TWXbXWXbTWY82R3IUQlpFasQm/1/+NaakdsDvwCxs2rMaa5moWDy/bBK+1TgP2KaUq5lI8QohcZmdrw4C2vrQYMIWBpWbQe6MLz07bzpUdcyFeCgDmZaYWGzuklFqrlFpy62XuwIQQucuzdGEm9u3E5119SIu/hNvqN2FSfdj3mxQvy6NM6YNvmtlyrXWO35GRPnghrENamsYm5ghpi9/AJmonVzyaUeyZSVC0vKVDE3d5qD54pZSnUqqJ1npjxheG+YCjzBWsEMLybGwUnN3HqctJjE/pgmPUNq6Pb0DclcuWDk08gOy6aMYB1zJZfiN9nRAiv9o/D/4cSJUb+3jFdhkzUtryfuILtBy/hSX7zqCvnbN0hMIE2SX4ylrr/Xcv1FqHA5XNFpEQwvLWjoLkBABc1E3esF/CK3bLcE+JZtfqX2F8Xdg8DlJTLBunyFZ2Cd4pm3XOOR2IEMKKxN3bC+ttc4qFtu8x4PknUZ6tYM1HXBoXTEr0PgsEKEyRXYLfqZR65e6FSqmXkSdZhcjfsriZauvmQUn3StDtJzb4jkFfjYbvm3P2rxyvHi5yQHaFoQcDC5VS3bmd0AMBB6CLmeMSQlhSyw9JWTwAu9RE46IUWyfsWn5oeKMUTbv0YW2lYBKXvsvGrZdxTTvEW228cHWUevPWIst/Ca31eaCxUqo5UCd98V9a63W5EpkQwmIWpTZhc3IfBvMr7iqGM7oE49KeJTi1CZ3T2yilaBVQi6vef7B9xb/M3BqJz9n5dK1wHVoMB0dXS34EgYkTfuQWGQcvhHVo8vk6omMT7lnu4ebMlndbZLrNrlNXqHFgDIXDJ5JSuDzXWn9NMd925g61wHukCT+EEAXPmUySe3bLAQIqFaPwE5/Ci8u5lAjFFnTj2Pc9Sbt+xVxhivuQBC+EuIe7W+YD5bJafodKjbn58iYWF+5GpailjPxhLofPZfZIjTA3SfBCiHsMbeuFs73tHcuc7W0Z2tbLpO0rlS1Bxze/Y3XrlSyJ86T9hDAOrpgO8RfMEa7IgiR4IcQ9OtfzYHRXHzzcnFEY+t5Hd/Whcz0Pk/ehlOLx4PqsfasZr9Yviveu4TCxPjfDf5LiZblEbrIKIXLHxVvFy3bwb6Egynafipt7NUtHlefJTVYhhOWVqkFyr2Wsrfw/KsTvg2mhLP77sEwuYkaS4IUQucbR3p6WvYdzrvsGfiz6BoMWHqPH9L+5cv4/S4eWL8kjZ0KIXFetRm0Ge9ai9I7/OLNjIW7TPoNm70DjgWBrb+nw8g25ghdCWISNjaJHw0oMffFZlFc7WDuKyM8bELE7zNKh5RuS4IUQFqUKl4VnZvNfq+9wTY6hxuKOrJz6NlcTky0dWp4nCV4IYRUqBj+L8+BdHCj5OKtPK1p9vZHlB87KTdhHIH3wQgirUcitJPUG/IxtVCwR8w9waf1k+C8BWn0EjoUtHV6eI1fwQgir41vejSX9m/B0DVvUzh9ImdiAlYt+IjVNruYfhCR4IYRVsrO1wandCHhpJXEp9rTd+wYbv3iSf45HWjq0PEMSvBDCulVsQPE3t3PE6zVCb27g0x/n8elfEdxIkvlg70cSvBDCuu2fh5pYnxqHp3GjUEUqVK7B92EnWf/7JLh2ztLRWTVJ8EII67V/Hvw5EOJOA5oi108y+sLrLGh6kccjv4BJQZzb+AMXrybed1cFkSR4IYT1WjsKku+aZCQ5Af9/x6Be24QuXZuy69/i2Det+HPDVtLkJuwdJMELIaxXXFTWy0t6onov42LTz/BTxwhe/zS9p67j2AWZXOQWSfBCCOtVtHz2y21sKNX8DZwG7eAf/xHsu5jKY+PD2B8RkWshWjNJ8EII69XyQ7C/a5pAe2fD8gyUW0Uad3qFtW815Ys60fjMbwqbviLu2o1cDNb6SIIXQlgv32egwwQoWgFQhv92mGBYnomSro507dAZVbM9rPuE8183ZPycecTeSMrduK2EJHghhFVblNqEJjcnUCXxZ5rcnMCi1CbZb+BaCp6eyc0n51DO/jpvHHuNn8cMZPHe6AJX10YSvBDCai3aE817Cw4QHZuABqJjE3hvwQEW7Ym+77aOOpHCzo5cw4Xk5BQG/bqXnj/uKFAPSEmxMSGE1fpq5WESklPvWJaQnMpXKw9nPwH4rfHzyQkUUzDA5g/cHG/gGlsC51W/QasRaMfCKKXM/AksSxK8EMJqnYlNeKDlRneNn7dVmt78BUlFIPwaKf8uZ7Tta3R4qjd+FdxyMGLrIl00Qgir5e7m/EDLjbIaP3/zGry8miTbQgyP+4iT07rz5YItxN/Mn902kuCFEFZraFsvnO1t71jmbG/L0LZe2W+Y3fj5CvVxGbCFm03+Rwe7v9kTvoVWX29k1aH8V9dGErwQwmp1rufB6K4+eLg5owAPN2dGd/XJvv8d7j9+3s4Rx9bDsRtygLdffwU3F3vid/wEV8+a5XNYirKmYUOBgYE6PDzc0mEIIfKD/fMMffFxUYYr95YfZjl+PvnaJey+rYtStkQGvsumQo/RvWFlbG2s/yasUmqX1jow03WS4IUQAog5Dn8OgsgwtqR6M6f0mwx+ug01yxaxdGTZyi7BSxeNEEIAlKgGPZegnxhHkGMkX8QMotuE1Xy54l8S7xqqmVfIMEkhhLjFxgYV+CL21dtge3wrbY57MnnDcTwd4+javIGlo3tgkuCFEOJuRT1w9X+ar/zhtbKHqba+F6ih7KrQi0plilHS1dHSEZpEumiEECIbnv4tUN6dYcNnuP3UmkFfT2de+Ok8UddGErwQQmSnUEl48gd47lcquiQxW7/P6YUjeP77vzlxMd7S0WVLErwQQpjC6zHsB+zAJqAXDQP8OXgmjnbjwzhuxUlehkkKIcRDuHA1kaNLv6ax6wVUm1FcSHakdGGnXI8ju2GScpNVCCEeQukiTpQup2DTbFIOr+Sjqy9QzL8j77SrSVFne0uHB5ixi0Yp5aSU2qGU2qeUOqSUGmmuYwkhhEU0HwZ91mDjUowptl/ScPfbPPX1EpbuP2MVN2HN2Qd/E2ihta4L+AHtlFINzXg8IYTIfR4B2Ly2EZoN4wn7cAJdztH/lz28MmsnqWmWTfJm66LRhl9ft+4+2Ke/LP8rTQghcpqdAzR7B5uAXnzsUppqWyMpd3IBttfcoWh5tNYWmVzErKNolFK2Sqm9wAVgtdb670zavKqUCldKhV+8eNGc4QghhHkVLoudrQ19AtxoHzUOJjUkcuVEOn0bxoGouFwPJ1dG0Sil3ICFwACt9cGs2skoGiFEvnH5pKF42cmNhCtvhia+TMsmjRjSugaFHHOu88Tixca01rHABqBdbhxPCCEsrngV6LkYOkwgwOE0y1w+ZO7mCNqM3cSGwxdyJQRzjqIplX7ljlLKGWgF/Guu4wkhhNVRCgJ6od7YgfOTU5j1egtcHGw5d+pIrhzenOPgywGzlFK2GH6RzNNaLzXj8YQQwjoVKQe1OxIILGt7Dbv5vcD+LVYW686lm/Bc/YrYmGFyEXOOotkP1DPX/oUQIi+yr9wI6jwJG7/A1+FX+l17CTfnbrT3LZfjx5JaNEIIkZsKlYCu0+D53ynrlMICxxE8Zr/LLIeSUgVCCGEJNdqg+m2HLeNR1Zqb5RCS4IUQwlKcikDL4WbbvXTRCCFEPiUJXggh8ilJ8EIIkU9JghdCiHxKErwQQuRTkuCFECKfkgQvhBD5lCR4IYTIp3KlHryplFIXgVMPuXlR4EEr6puyTXZtslqX2fL7Lbt7fUng0n1iexiWOE/Zrb97uSnnLuP7vHae7tfuUb5TljhPWcWWE9vIeTJtm+pa66KZrtFa54sXMM0c22TXJqt1mS2/37K71wPh+eU8Pci5MuXc3XXe8tR5ul+7R/lOWeI8mfNcyXl69POUn7po/jTTNtm1yWpdZsvvt+xh4n8YljhP2a2/e7kp5y43zpW5ztP92j3Kd8oS5+lhj2PJ//cKzHmyqi4acZtSKlxnMQ2XuE3Ok2nkPJkmv52n/HQFn99Ms3QAeYScJ9PIeTJNvjpPcgUvhBD5lFzBCyFEPiUJXggh8ilJ8EIIkU/JjE55gFKqGfAxcAj4VWu9wZLxWDOllA2Gc1UEw5jmWRYOySoppUKA7hhyQG2tdWMLh2SVlFIVgYkYHn46orX+3MIhPRC5grcQpdSPSqkLSqmDdy1vp5Q6rJQ6ppR6N32xBuIBJyAqt2O1tAc8V50ADyCZAnauHuQ8aa3DtNavA0uBAvVL8AG/TzWAv7TWLwG1cz3YR2Wup7bkdd+nz0IBf+BghmW2wHGgKuAA7MPwpbJJX18G+NnSsVv5uXoXeC29zR+Wjt1az1OG9fOAIpaO3VrPE1ACWA+sA160dOwP+pIreAvRWm8CLt+1OAg4prU+obVOAn4FOmmt09LXXwEcczFMq/Ag5wrDVfuV9DapuRel5T3gebrV/RCntb6au5Fa1gOepxeBj7TWLYD2uRvpo5MEb108gNMZ3kcBHkqprkqp74A5GPoDRRbnClgAtFVKfQtsskRgViar8wTwMjAj1yOyTlmdpxXAQKXUVCDSAnE9ErnJal1UJsu01noBhsQlbsvqXN3AkLiEQabnCUBr/VEux2LNsvo+HQSeyu1gcopcwVuXKKBChvflgTMWisXaybkyjZwn0+TL8yQJ3rrsBKorpaoopRyAZ4ElFo7JWsm5Mo2cJ9Pky/MkCd5ClFJzgW2Al1IqSin1stY6BegPrAT+AeZprQ9ZMk5rIOfKNHKeTFOQzpMUGxNCiHxKruCFECKfkgQvhBD5lCR4IYTIpyTBCyFEPiUJXggh8ilJ8EIIkU9Jghd5klIqVSm1Vyl1UCn1u1LKxQpiaqaUkrrqwmpIghd5VYLW2k9rXQdIAl43ZSOllDnrLzUDHijBmzkeUcDJg04iT1JKxWutXdN/fh3wBZYDH2Co5x0DdNdan1dKjQDcgcoYZuYZhqEyZ6H03fXXWm9NnzlrJHAe8MNQ4O0AMAhwBjprrY8rpUoBU4GK6dsPBqKB7RhKFF8EBgD/3t1Oa70lk3g+xVDV0QHDRdeTWuujOXCaRAEnVw8iT0u/An4MQ1nXzUBDrbVWSvUB3gbeSm8aAARrrRPSu3Naa60TlVLVgblAYHq7ukAtDPXCTwA/aK2DlFKDMCTtwcB4YKzWenN6TfWVWuta6SVl47XWY9Jj++Xudun7vjueb4HxWuuf0+ug2JrnbImCRhK8yKuclVJ7038OA6YDXsBvSqlyGK6GT2Zov0RrnZD+sz0wUSnlh+GKu0aGdju11mcBlFLHgVXpyw8AzdN/bgXUVspYYbaIUqpwJjFm1y5jPNuA95VS5YEFcvUucookeJFXJWit/TIuSL8S/kZrvSS9u2VEhtXXM/w8BEM3TF0MXSKJGdbdzPBzWob3adz+/8UGaJQhQd86/t0xZtfOGI/W+hel1N8YZgxaqZTqo7Ved/fOhHhQcpNV5CdFMfSFA/S6T7uz6VMhvsCDd4mswlB5EID0vwQArgGFTWh3B6VUVeCE1noChhK1vg8YjxCZkgQv8pMRwO9KqTAMNy+zMhnopZTajqF75no2bTMzEAhUSu1XSkVwewTPn0CX9OGbIdm0u1s34GB6l1NNYPYDxiNEpmQUjRBC5FNyBS+EEPmUJHghhMinJMELIUQ+JQleCCHyKUnwQgiRT0mCF0KIfEoSvBBC5FOS4IUQIp/6Pw0WFacWi8rpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "gpt2_param = np.array([\n",
    "    50112,\n",
    "    198528,\n",
    "    309600,\n",
    "    1779840,\n",
    "    4235616,\n",
    "    7108352,\n",
    "    16029120,\n",
    "    45872064,\n",
    "], dtype = 'int64')\n",
    "\n",
    "gpt2_y = np.array([\n",
    "    6.038,\n",
    "    5.565,\n",
    "    5.46,\n",
    "    4.735,\n",
    "    4.318,\n",
    "    3.997,\n",
    "    3.61,\n",
    "    3.23,\n",
    "])\n",
    "\n",
    "leap_param = np.array([\n",
    "    49856,\n",
    "    198016,\n",
    "    308960,\n",
    "    1776768,\n",
    "    4229344,\n",
    "    7099136,\n",
    "    16012480,\n",
    "    45838016,\n",
    "    69308416,\n",
    "], dtype = 'int64')\n",
    "\n",
    "leap_y = np.array([\n",
    "    6.115,\n",
    "    5.721,\n",
    "    5.601,\n",
    "    4.646,\n",
    "    4.252,\n",
    "    4.008,\n",
    "    3.683,\n",
    "    3.329,\n",
    "    3.223,\n",
    "])\n",
    "\n",
    "lstm_x = np.array([\n",
    "])\n",
    "\n",
    "lstm_y = np.array([\n",
    "])\n",
    "\n",
    "def powerlaw(n, n_c, a):\n",
    "    return (n_c / n)**a\n",
    "\n",
    "x = 10**np.arange(start = 4.3, stop = 8.5, step = .1, dtype = 'float64')\n",
    "\n",
    "plt.loglog()\n",
    "plt.yticks([2, 3, 4, 5, 6, 7], labels = [2, 3, 4, 5, 6, 7])\n",
    "\n",
    "plt.scatter(x = gpt2_param, y = gpt2_y)\n",
    "(n_c, a), _ = curve_fit(powerlaw, gpt2_param, gpt2_y, maxfev=10000, p0 = np.array([9e13, .076]))\n",
    "plt.plot(x, powerlaw(x, n_c, a), label = f'GPT2 powerlaw alpha = {-a:.3}', linestyle = '--')\n",
    "print(\"GPT2\", n_c, a, f'{powerlaw(10**9, n_c, a):.4}')\n",
    "\n",
    "plt.scatter(x = leap_param, y = leap_y)\n",
    "(n_c, a), _ = curve_fit(powerlaw, leap_param, leap_y, maxfev=10000, p0 = np.array([9e13, .076]))\n",
    "plt.plot(x, powerlaw(x, n_c, a), label = f'LEAP powerlaw alpha = {-a:.2}', linestyle = '--')\n",
    "print(\"LEAP\", n_c, a, f'{powerlaw(10**9, n_c, a):.4}')\n",
    "\n",
    "plt.xlabel(\"Parameters\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('param_scale.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-84fbe372e4c9>:58: RuntimeWarning: invalid value encountered in power\n",
      "  return (n_c / n)**a\n",
      "<ipython-input-2-84fbe372e4c9>:58: RuntimeWarning: invalid value encountered in power\n",
      "  return (n_c / n)**a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 5.2206617991817826e+26 0.05117541902611786 8.067\n",
      "LEAP 2.4920167331379797e+26 0.05276556024262718 8.278\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt2_flos = np.array([\n",
    "    150249406464,\n",
    "    1646670643200,\n",
    "    3568494182400,\n",
    "    74808640143360,\n",
    "    338150979403776,\n",
    "    832464675667968,\n",
    "    3426220553011200,\n",
    "    21348380048228352,\n",
    "], dtype = 'int64')\n",
    "\n",
    "leap_flos = np.array([\n",
    "    148869218304,\n",
    "    1639990689792,\n",
    "    3555422699520,\n",
    "    74581272428544,\n",
    "    337286462177280,\n",
    "    830556657942528,\n",
    "    3420105859399680,\n",
    "    21320987684634624,\n",
    "    42697213473718272,\n",
    "], dtype = 'int64')\n",
    "\n",
    "x = 10**np.arange(start = 10.5, stop = 17.7, step = .1, dtype = 'float64')\n",
    "plt.loglog()\n",
    "plt.yticks([3, 4, 5, 6, 7], labels = [3, 4, 5, 6, 7])\n",
    "\n",
    "#plt.plot(gpt2_flos, gpt2_y, \".-\", color = 'C0', label = \"GPT2 linear interpolation\", markersize = 10)\n",
    "plt.scatter(x = gpt2_flos, y = gpt2_y)\n",
    "(n_c, a), _ = curve_fit(powerlaw, gpt2_flos, gpt2_y, maxfev=10000, p0 = np.array([9e30, .05]))\n",
    "plt.plot(x, powerlaw(x, n_c, a), label = f'GPT2 powerlaw alpha = {-a:.3}', linestyle = '--')\n",
    "print(\"GPT2\", n_c, a, f'{powerlaw(10**9, n_c, a):.4}')\n",
    "\n",
    "#plt.plot(leap_flos, leap_y, \".-\", color = 'C1', label = \"LEAP linear interpolation\", markersize = 10)\n",
    "plt.scatter(x = leap_flos, y = leap_y)\n",
    "(n_c, a), _ = curve_fit(powerlaw, leap_flos, leap_y, maxfev=10000, p0 = np.array([9e30, .05]))\n",
    "plt.plot(x, powerlaw(x, n_c, a), label = f'LEAP powerlaw alpha = {-a:.2}', linestyle = '--')\n",
    "print(\"LEAP\", n_c, a, f'{powerlaw(10**9, n_c, a):.4}')\n",
    "\n",
    "plt.xlabel(\"FLOPs\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('compute_scale.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105268829"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# to count tokens, comes from https://huggingface.co/docs/tokenizers/components\n",
    "whitespace_regex = re.compile(\"\\w+|[^\\w\\s]+\")\n",
    "\n",
    "# get number of tokens\n",
    "total_tokens = 0\n",
    "for row in raw_datasets[\"train\"][\"text\"]:\n",
    "    total_tokens += len((whitespace_regex.split(row)))\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 33408, with commas 33,408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 369664, with commas 369,664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='181' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 74098409472\n",
      "Human Readable: 74,098,409,472\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 15.131314277648926, 'eval_runtime': 3.2103, 'eval_samples_per_second': 74.137, 'eval_steps_per_second': 37.068, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 64, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 74688, with commas 74,688\n",
      "NUMBER OF TOKENS: 670720, with commas 670,720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='328' max='328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [328/328 00:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 300568412160\n",
      "Human Readable: 300,568,412,160\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.494235038757324, 'eval_runtime': 3.5429, 'eval_samples_per_second': 67.177, 'eval_steps_per_second': 33.589, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 96, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 132352, with commas 132,352\n",
      "NUMBER OF TOKENS: 1024000, with commas 1,024,000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>13.526600</td>\n",
       "      <td>8.492445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 813170688000\n",
      "Human Readable: 813,170,688,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.3527250289917, 'eval_runtime': 3.4871, 'eval_samples_per_second': 68.252, 'eval_steps_per_second': 34.126, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 128, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 layers\n",
      "NON EMBEDDING PARAMETERS: 206400, with commas 206,400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 1423360, with commas 1,423,360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [695/695 00:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>13.012000</td>\n",
       "      <td>7.334210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 1762689024000\n",
      "Human Readable: 1,762,689,024,000\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.193444728851318, 'eval_runtime': 3.7914, 'eval_samples_per_second': 62.774, 'eval_steps_per_second': 31.387, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 160, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 layers\n",
      "NON EMBEDDING PARAMETERS: 1186176, with commas 1,186,176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOKENS: 5188608, with commas 5,188,608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2534' max='2534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2534/2534 10:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>14.231200</td>\n",
       "      <td>6.937136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.190400</td>\n",
       "      <td>5.915351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.678500</td>\n",
       "      <td>5.660433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.502000</td>\n",
       "      <td>5.531826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.436800</td>\n",
       "      <td>5.505051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============TOTAL TRAINING FLOATING POINT OPERATIONS===============\n",
      "\n",
      "Numeric form: 36927613698048\n",
      "Human Readable: 36,927,613,698,048\n",
      "\n",
      "===============TEST SET CROSS ENTROPY LOSS EVALUATION===============\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/119 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.423725605010986, 'eval_runtime': 12.5413, 'eval_samples_per_second': 18.977, 'eval_steps_per_second': 9.489, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_training(hidden_size = 192, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(hidden_size = 224, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(hidden_size = 256, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(hidden_size = 320, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(hidden_size = 448, rnn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
